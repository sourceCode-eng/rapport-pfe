\thispagestyle{mainmatter}

\section{Objectifs et contexte du projet}
\subsection{Contexte et enjeux du projet}

Dans un environnement où les systèmes d'information deviennent de plus en plus complexes et interconnectés, la gestion manuelle des infrastructures techniques pose de nombreux défis. Les entreprises doivent faire face à des exigences croissantes en matière de sécurité, de disponibilité et de performance, tout en cherchant à optimiser leurs coûts et à réduire les délais de mise en production. Cette évolution rend la gestion des infrastructures non seulement complexe, mais parfois inefficace, voire impossible à grande échelle.

Dans ce contexte, l'automatisation des processus d'infrastructure et l'adoption de solutions DevOps sont devenues des priorités stratégiques. La maîtrise de l'infrastructure et des processus de déploiement passe alors d'un luxe à une nécessité afin de soutenir rapidement et efficacement la croissance continue des besoins de l'entreprise.

Cependant, automatiser le déploiement des services ne suffit plus. Il est essentiel de garantir à tout moment leur bon fonctionnement grâce à des mécanismes de supervision et de contrôle rigoureux. La mise en place de solutions de \emph{monitoring}, de \emph{logging} et de \emph{tracing} permet de disposer d'une visibilité complète sur l'état des systèmes, d'anticiper les incidents et de réagir rapidement en cas d'anomalie. Ces dispositifs contribuent également à renforcer la traçabilité et à répondre aux impératifs de conformité réglementaire.

En parallèle, le renforcement de la cybersécurité constitue un enjeu majeur. La multiplication des points d'entrée et l'interconnexion croissante des services exposent l'infrastructure à de nouvelles menaces qu'il convient de prévenir et de détecter de manière proactive.

Ce mémoire s'inscrit dans cette dynamique, avec pour objectif principal de concevoir et mettre en place une solution automatisée, sécurisée et résiliente permettant de déployer, superviser et maintenir l'infrastructure technique de l'entreprise Oneex. Le projet vise à répondre aux besoins opérationnels croissants, à réduire les erreurs manuelles et à garantir un haut niveau de qualité de service et de transparence, tout en respectant les contraintes strictes de sécurité et de conformité réglementaire.

\subsection{Scénarios de référence et hypothèses de travail}

La conception d’une solution d’automatisation et de sécurisation des infrastructures ne peut se limiter à une approche purement théorique. Elle doit s’appuyer sur l’analyse de situations concrètes, issues de l’expérience opérationnelle et des incidents effectivement rencontrés dans des environnements comparables à celui de l’entreprise Oneex.
Dans cette perspective, plusieurs scénarios représentatifs ont été identifiés afin d’illustrer les risques, les besoins et les priorités du projet.
Ces scénarios reflètent des problématiques récurrentes observées lors de la gestion quotidienne des systèmes : cohérence entre les environnements, gestion des défaillances matérielles ou logicielles, continuité de service, sécurité des données et qualité de vie au travail des équipes techniques. La prise en compte de ces aspects vise à construire un environnement plus fiable, plus transparent et moins générateur de stress pour les équipes Dev et Ops. La suite de ce chapitre présente ces scénarios, qui serviront de base aux choix techniques et organisationnels retenus pour la solution cible.

\paragraph{\textbf{Divergences entre environnements}}

Dans de nombreux contextes, la configuration manuelle des serveurs opérée par plusieurs équipes successives conduit progressivement à des écarts significatifs entre les environnements de développement, de test et de production. Ces divergences concernent notamment :

\begin{itemize}
	\item Les versions des systèmes d'exploitation, des librairies et des dépendances logicielles.
	\item Les paramètres réseau tels que l'ouverture de ports ou l'attribution d'adresses IP.
	\item La définition des règles de sécurité (droits d'accès, politiques de pare-feu).
\end{itemize}

Ces différences génèrent fréquemment des dysfonctionnements applicatifs lors des bascules d'environnement, compliquent la reproduction des incidents constatés et placent l’équipe opérations sous forte pression en raison de délais de résolution prolongés. Si elles provoquent des interruptions de service, ces situations peuvent également nuire à l’image de sérieux et de fiabilité de l’entreprise auprès de ses clients et partenaires.

\paragraph{\textbf{Gestion hétérogène des secrets}}

Il est fréquent de constater l’absence de processus unifié de gestion des informations sensibles (identifiants, clés d’API, certificats). Ces éléments sont souvent stockés et partagés de façon informelle, par exemple :

\begin{itemize}
	\item Sous forme de fichiers non chiffrés sur les postes individuels.
	\item Par échange de courriels non sécurisés.
	\item Par messagerie instantanée, sans traçabilité ni archivage structuré.
\end{itemize}

Une telle organisation expose les infrastructures à des risques accrus de fuite d’informations critiques et complique la gestion opérationnelle lors des renouvellements ou révocations des secrets. Elle entraîne également un déficit de traçabilité sur les accès et les modifications, et augmente la probabilité de perdre définitivement certains secrets sensibles. Ces défaillances peuvent aller jusqu’à bloquer totalement l’accès aux ressources stratégiques de l’entreprise, y compris lors d’incidents pourtant courants, comme le vol ou la panne d’un poste administrateur.

\paragraph{\textbf{Déficit d'observabilité}}

Il est également courant qu’aucun dispositif unifié de supervision et de journalisation n’ait été mis en place. Dans ce contexte, plusieurs limitations apparaissent :

\begin{itemize}
	\item L’absence de collecte systématique des métriques de performance.
	\item La dispersion des journaux applicatifs sur des serveurs multiples, sans agrégation centralisée.
	\item Le manque de mécanismes de corrélation des événements entre composants.
\end{itemize}

Un tel déficit d’observabilité réduit considérablement la capacité à détecter précocement les anomalies, à diagnostiquer efficacement les causes racines et à mesurer le respect des engagements de qualité de service.

\paragraph{\textbf{Processus de déploiement manuel et long}}

Dans certaines organisations, le déploiement d’une infrastructure repose encore sur des opérations entièrement manuelles qui sont souvent réalisées en dehors des horaires de service (la nuit ou pendant les week-ends) afin de limiter l’impact sur les utilisateurs.. La création d’un nouvel environnement peut alors nécessiter plusieurs jours de travail successif :

\begin{enumerate}
	\item Préparation et allocation des ressources matérielles ou virtuelles.
	\item Installation des systèmes d’exploitation et des dépendances logicielles.
	\item Paramétrage des droits d’accès et des configurations de sécurité.
	\item Vérification manuelle de la conformité et du bon fonctionnement des services.
\end{enumerate}

Ces processus induisent des délais importants, une faible reproductibilité et une exposition accrue aux erreurs humaines.

\paragraph{\textbf{Risques opérationnels associés}}

Ces scénarios convergent vers un ensemble de risques concrets et bien identifiés :

\begin{itemize}
	\item L’allongement des délais de livraison et la perte d’agilité opérationnelle.
	\item L’augmentation de la surface d’attaque due à des configurations hétérogènes et non sécurisées.
	\item La probabilité accrue d’erreurs de configuration.
	\item La difficulté à garantir la sécurité des environnements et la confidentialité des données sensibles.
	\item L’impossibilité de disposer d’une vision globale et en temps réel de l’état de l’infrastructure.
	\item Des temps de diagnostic et de réaction allongés, rendant plus difficile la résolution rapide des problèmes critiques.
\end{itemize}

Ces constats renforcent l’intérêt d’intégrer dès la conception des mécanismes de \emph{monitoring}, de \emph{logging} et de \emph{tracing} afin de renforcer la transparence et la capacité de réaction face aux incidents.

\paragraph{\textbf{Justification des orientations retenues}}

L’analyse de ces situations et des risques associés conduit à considérer comme prioritaires les axes suivants :

\begin{itemize}
	\item L’automatisation des processus de déploiement et de configuration, pour réduire les délais et améliorer la cohérence.
	\item La centralisation et la sécurisation de la gestion des secrets et des accès, afin de prévenir les fuites d’informations sensibles.
	\item Lorsque cela est possible, l’utilisation de mécanismes de génération et de rotation automatique de secrets temporaires (par exemple, des credentials ou des clés TLS via des solutions de type \emph{Vault}).
	\item La mise en place d’une gestion stricte des droits d’accès, fondée sur le principe du moindre privilège et les bonnes pratiques du \emph{Zero Trust}.
	\item L’intégration d’outils d’observabilité pour assurer un suivi continu et une traçabilité complète des opérations.
	\item Le renforcement des contrôles de sécurité et la conformité avec les normes en vigueur.
\end{itemize}

Ces orientations constituent le socle sur lequel s'appuie le projet présenté dans ce mémoire.

\begin{longtable}{|p{5cm}|p{5cm}|p{5cm}|}
	\caption{Synthèse des cas d'usage avant et après la mise en place de la solution} \label{tab:avant_apres}                                                                                           \\
	\hline
	\textbf{Aspect}                                                                                                              & \textbf{Situation initiale} & \textbf{Situation après mise en place} \\
	\hline
	\endfirsthead
	\hline
	\textbf{Aspect}                                                                                                              & \textbf{Situation initiale} & \textbf{Situation après mise en place} \\
	\hline
	\endhead
	\hline
	\multicolumn{3}{r}{\textit{Suite en page suivante}}
	\endfoot
	\hline
	\endlastfoot
	\textbf{Cohérence des environnements}                                                                                        &
	Configurations manuelles et divergentes entre développement, test et production, générant des écarts difficiles à maîtriser. &
	Automatisation des déploiements garantissant la standardisation et la reproductibilité des environnements.                                                                                          \\
	\hline
	\textbf{Gestion des secrets}                                                                                                 &
	Stockage informel et non sécurisé des identifiants, échanges par email ou messagerie instantanée.                            &
	Centralisation sécurisée des secrets avec rotation automatique et contrôle des accès.                                                                                                               \\
	\hline
	\textbf{Observabilité}                                                                                                       &
	Absence d’agrégation centralisée des journaux et des métriques, difficultés de diagnostic.                                   &
	Mise en place d’outils de supervision, de journalisation et de traçabilité unifiés.                                                                                                                 \\
	\hline
	\textbf{Déploiement des infrastructures}                                                                                     &
	Processus manuel long (plusieurs jours), faible reproductibilité et risque élevé d’erreurs humaines.                         &
	Automatisation complète permettant des déploiements rapides et contrôlés.                                                                                                                           \\
	\hline
	\textbf{Sécurité opérationnelle}                                                                                             &
	Droits d’accès gérés de façon hétérogène et peu contrôlée, exposition accrue aux attaques.                                   &
	Application du principe du moindre privilège et d’une approche Zero Trust, contrôles renforcés.                                                                                                     \\
	\hline
	\textbf{Temps de réaction aux incidents}                                                                                     &
	Diagnostic lent et difficile en cas d’anomalie ou d’incident critique.                                                       &
	Observabilité en temps réel et capacité d’investigation rapide grâce à la centralisation des informations.                                                                                          \\
	\hline
\end{longtable}

\subsection{Les besoins fonctionnels}

Les besoins fonctionnels décrivent l'ensemble des fonctionnalités attendues de la solution envisagée, ainsi que les objectifs opérationnels qui en découlent. Ils visent à garantir la cohérence, la sécurité, la traçabilité et la résilience de l'infrastructure et des applications. Ces besoins peuvent être regroupés autour de plusieurs axes principaux :

\paragraph{\textbf{Provisioning et configuration des ressources}}

\begin{itemize}
	\item \textbf{Automatisation du provisioning des ressources} : permettre la création, la configuration et la suppression des composants d'infrastructure de manière déclarative et reproductible, afin de réduire les délais et d'éviter les interventions manuelles.
	\item \textbf{Gestion centralisée et cohérente des configurations} : mettre en œuvre un mécanisme d'orchestration permettant d'installer les dépendances logicielles, d'appliquer les paramétrages requis et de maintenir l'uniformité entre les différents environnements.
\end{itemize}

\paragraph{\textbf{Déploiement et mise à jour des applications}}

\begin{itemize}
	\item \textbf{Déploiement applicatif automatisé et contrôlé} : intégrer un processus déclenchant les déploiements depuis des référentiels versionnés et assurant la synchronisation permanente entre le code source et les environnements cibles.
\end{itemize}

\paragraph{\textbf{Supervision et observabilité}}

\begin{itemize}
	\item \textbf{Supervision proactive et alertes en temps réel} : disposer d'un système de surveillance permettant de collecter les métriques de performance, de visualiser l'état des services et de générer des alertes en cas d'incident.
	\item \textbf{Détection précoce des anomalies} : mettre en place des mécanismes d'analyse continue et d'identification des écarts de comportement afin d'anticiper les incidents et de réduire leur impact.
	\item \textbf{Journalisation centralisée} : assurer la collecte, le stockage et la consultation unifiée des journaux système et applicatifs.
\end{itemize}

\paragraph{\textbf{Sécurité et gestion des accès}}

\begin{itemize}
	\item \textbf{Gestion sécurisée et dynamique des secrets} : intégrer un système centralisé de stockage, de chiffrement et de distribution des informations sensibles, avec des mécanismes de rotation automatique et de durée de vie limitée des secrets lorsque cela est possible.
	\item \textbf{Séparation stricte des environnements} : organiser l'infrastructure en environnements distincts (développement, test, pré-production, production) afin de garantir leur isolation et de limiter les risques de contamination croisée.
\end{itemize}

\paragraph{\textbf{Résilience et continuité de service}}

\begin{itemize}
	\item \textbf{Correction automatique des incidents et des défaillances} : prévoir des processus d'auto-remédiation capables de restaurer l'état nominal des services, par exemple par le redémarrage ou le reprovisionnement automatisé des ressources en cas de panne.
\end{itemize}

\paragraph{\textbf{Interface de pilotage}}

\begin{itemize}
	\item \textbf{Interface unifiée d'administration} : proposer une interface utilisateur et/ou une API permettant d'interagir avec la plateforme de manière sécurisée et traçable.
\end{itemize}

Ces besoins fonctionnels constituent la base de la solution à concevoir, en intégrant les outils et les pratiques DevOps adaptés pour répondre aux enjeux opérationnels et réglementaires de l'entreprise.

\paragraph{\textbf{Les besoins non fonctionnels}}

Les besoins non fonctionnels définissent les critères de qualité, de performance, de sécurité et de conformité que la solution doit respecter de manière transversale. Ces exigences sont essentielles pour garantir la fiabilité, la pérennité et la valeur ajoutée de la plateforme. Elles peuvent être regroupées selon plusieurs dimensions complémentaires.

\paragraph{\textbf{Qualité de service et performance}}

\begin{itemize}
	\item \textbf{Haute disponibilité} : garantir un taux de disponibilité supérieur à 99,9\,\% pour les services critiques, en prévoyant des mécanismes de redondance, de bascule automatique et de tolérance aux pannes.
	\item \textbf{Performance} : assurer des temps de réponse optimaux et constants, y compris en période de forte charge, afin de préserver la qualité d'expérience des utilisateurs et le respect des engagements contractuels (SLA).
	\item \textbf{Scalabilité} : permettre une montée en charge fluide et progressive de l'infrastructure, que ce soit en termes de volume de données, de nombre d'utilisateurs ou de capacités de traitement.
	\item \textbf{Réduction du temps de mise en production} : optimiser les processus afin de diminuer significativement les délais nécessaires au déploiement de nouvelles fonctionnalités ou de correctifs.
\end{itemize}

\paragraph{\textbf{Sécurité et protection des données}}

\begin{itemize}
	\item \textbf{Sécurité renforcée} : garantir la protection des données sensibles, la confidentialité des échanges et la résilience face aux attaques, en appliquant les principes de \emph{security by design} et en intégrant les contrôles de sécurité dès la conception.
	\item \textbf{Gestion stricte des droits d'accès} : appliquer le principe du moindre privilège, segmenter les privilèges et mettre en œuvre des mécanismes de contrôle d'accès granulaires et auditables, conformément aux approches de type Zero Trust.
	\item \textbf{Réduction du mouvement latéral} : cloisonner les composants et les services pour limiter les possibilités de propagation en cas de compromission, et empêcher qu’un attaquant ayant compromis un service puisse accéder aux autres ressources du système.
	\item \textbf{Traçabilité et auditabilité} : conserver un historique détaillé, horodaté et inviolable de toutes les opérations critiques, des changements de configuration et des actions administratives.
	\item \textbf{Audits automatiques de conformité et d'intégrité} : générer périodiquement des rapports permettant de vérifier la cohérence des configurations, la robustesse des mécanismes de sécurité et le respect des politiques internes et réglementaires.
\end{itemize}

\paragraph{\textbf{Évolutivité et maintenabilité}}

\begin{itemize}
	\item \textbf{Maintenabilité} : faciliter l'application des mises à jour logicielles, l'évolution des configurations et l'intégration de nouvelles fonctionnalités, tout en minimisant les interruptions de service.
	\item \textbf{Source unique de vérité (Single Source of Truth)} : centraliser et versionner l'ensemble des configurations, des états d'infrastructure et de la documentation technique dans un référentiel unique, fiable et auditable.
	\item \textbf{Respect du principe DRY (Don’t Repeat Yourself)} : structurer les configurations et les processus de manière modulaire et réutilisable, afin d'éviter les duplications inutiles, de garantir la cohérence et de réduire le risque d'erreurs lors des modifications ou évolutions.
\end{itemize}

\paragraph{\textbf{Conformité réglementaire et normes applicables}}

\begin{itemize}
	\item \textbf{Conformité réglementaire} : respecter les obligations légales et les standards sectoriels en vigueur notamment RGPD, ANSII mais egalement ISO 27001, NIS2, etc. , ainsi que les exigences spécifiques à l'activité et aux données traitées.
\end{itemize}

\section{Fondements théoriques et méthodologiques}
\section{Architecture du projet}

L'architecture globale du projet repose sur une approche moderne, modulaire et automatisée, intégrant les principes de l'Infrastructure as Code, du GitOps, de la conteneurisation et de l'observabilité. Elle a été conçue pour répondre aux exigences de performance, de sécurité, de scalabilité et de maintenabilité en s'appuyant sur plusieurs principes de l’état de l’art et bonnes pratiques du génie logiciel et de l’ingénierie des plateformes

\begin{figure}[H]
	\centering
	\includegraphics[width=0.9\textwidth]{figures/architecture-globale.png}
	\caption{Schéma d'architecture globale}
\end{figure}

\subsection{Infrastructure virtualisée et provisioning automatisé}

L'infrastructure physique est virtualisée au moyen d'une plateforme Proxmox. La création des ressources a été entièrement automatisée via une démarche Infrastructure as Code.

\subsection*{Infrastructure as Code avec Terraform}

Terraform a permis de décrire et de provisionner l'ensemble des ressources suivantes de façon déclarative et reproductible :
\begin{itemize}
	\item Les machines virtuelles dédiées aux nœuds Kubernetes (masters et workers) et aux services utilitaires.
	\item Les réseaux virtuels, sous-réseaux et interfaces.
	\item Les volumes de stockage attachés aux instances.
	\item Les configurations initiales via cloud-init.
\end{itemize}

Les modules Terraform ont été organisés par domaines fonctionnels afin de favoriser leur réutilisation et leur évolutivité.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.8\textwidth]{figures/terraform-provisioning.png}
	\caption{Schéma du processus de provisioning automatisé avec Terraform}
\end{figure}

\subsection*{Configuration automatisée avec Ansible}

Après la création des ressources, Ansible assure la configuration des serveurs :
\begin{itemize}
	\item Installation et configuration du cluster Kubernetes.
	\item Déploiement des composants de monitoring et de sécurité.
	\item Configuration des services réseau et des paramètres système.
	\item Application des règles de sécurité renforcées.
\end{itemize}

Cette étape garantit l’homogénéité et la reproductibilité des environnements.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.8\textwidth]{figures/ansible-configuration.png}
	\caption{Processus d'automatisation de la configuration avec Ansible}
\end{figure}

\subsection{Orchestration et déploiement applicatif}

\subsection*{Cluster Kubernetes}

Kubernetes est le cœur de l’architecture d’orchestration. Il assure la gestion :
\begin{itemize}
	\item Du cycle de vie des conteneurs applicatifs.
	\item De l’équilibrage de charge et du scaling horizontal.
	\item De l’isolation des workloads.
\end{itemize}

\subsection*{Déploiement GitOps avec Argo CD}

Argo CD implémente une stratégie GitOps permettant :
\begin{itemize}
	\item Le déclenchement automatique des déploiements depuis un dépôt Git.
	\item La synchronisation continue des manifestes Kubernetes.
	\item La traçabilité complète des changements et la simplification des rollbacks.
\end{itemize}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.9\textwidth]{figures/gitops-argo-cd.png}
	\caption{Flux GitOps des déploiements avec Argo CD}
\end{figure}

\subsection{Observabilité et monitoring}

La supervision s'appuie sur un ensemble d’outils intégrés :

\begin{itemize}
	\item \textbf{Prometheus} pour la collecte des métriques et des alertes.
	\item \textbf{Grafana} pour la visualisation des indicateurs.
	\item \textbf{Loki} pour la centralisation des logs applicatifs et système.
	\item \textbf{Tempo} pour la gestion des traces distribuées.
\end{itemize}

Cette stack assure une observabilité complète et un diagnostic précis en cas d’incident.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.85\textwidth]{figures/observabilite-stack.png}
	\caption{Architecture de la stack d'observabilité}
\end{figure}

\subsection{Stockage distribué et persistance des données}

Le stockage persistant est assuré par Longhorn, qui fournit :
\begin{itemize}
	\item Des volumes répliqués tolérants aux pannes.
	\item Des snapshots automatisés et des fonctionnalités de restauration.
	\item Une intégration transparente avec Kubernetes.
\end{itemize}

\begin{figure} [H]
	\centering
	\includegraphics[width=.5\textwidth]{figures/how-longhorn-works.png}
	\caption{Stockage distribué avec Longhorn}
\end{figure}

\subsection{Gestion sécurisée des secrets}

Vault joue le rôle de coffre-fort centralisé :
\begin{itemize}
	\item Stockage chiffré des mots de passe, certificats et tokens.
	\item Génération dynamique de secrets temporaires et rotation de secrets.
	\item Politiques d’accès granulaires pour limiter les droits.
\end{itemize}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.8\textwidth]{figures/vault-gestion-secrets.png}
	\caption{Flux de gestion sécurisée des secrets avec Vault}
\end{figure}

\subsection{Sécurité réseau et accès administratifs}

La sécurité périmétrique est confiée à un pare-feu pfSense :
\begin{itemize}
	\item Contrôle des flux entrants et sortants via des règles spécifiques.
	\item Mise en place d’un VPN pour les accès administratifs.
	\item Surveillance active des connexions.
\end{itemize}

\begin{figure}[H]
	\centering
	\begin{tikzpicture}[
			node distance=2cm,
			box/.style={draw, rectangle, minimum width=3cm, minimum height=1cm, align=center},
			vm/.style={draw, rectangle, minimum width=2cm, minimum height=0.8cm, align=center}
		]
		% Nodes
		\node[box] (internet) {Internet};
		\node[box, below of=internet] (proxmox) {Proxmox Hyperviseur};
		\node[box, below of=proxmox] (pfsense) {VM pfSense \\ (Pare-feu / Routeur)};
		\node[box, below of=pfsense] (switch) {Réseau LAN Interne};
		\node[vm, left=1.5cm of switch] (vm1) {VM1};
		\node[vm, right=1.5cm of switch] (vm2) {VM2};
		% Arrows
		\draw[->] (internet) -- (proxmox);
		\draw[->] (proxmox) -- (pfsense);
		\draw[->] (pfsense) -- (switch);
		\draw[->] (switch) -- (vm1);
		\draw[->] (switch) -- (vm2);
	\end{tikzpicture}
	\caption{Architecture de sécurité réseau avec pfSense}
\end{figure}

\subsection{Services internes pour le cycle de vie applicatif}

Pour répondre aux besoins opérationnels des équipes, plusieurs services internes ont été déployés:
\begin{itemize}
	\item \textbf{GitLab} pour la gestion des dépôts, la CI/CD et la revue de code.
	\item \textbf{Harbor} comme registre privé de conteneurs.
	\item \textbf{YouTrack} pour le suivi des incidents et la gestion des tâches.
	\item \textbf{Nextcloud} pour le partage et l’archivage des documents.
\end{itemize}

Ces outils sont hébergés sur Kubernetes afin d’assurer leur haute disponibilité.

% Schéma services internes
\begin{figure}[H]
	\centering
	\includegraphics[width=0.85\textwidth]{figures/services-internes.png}
	\caption{Panorama des services internes}
\end{figure}

\subsection{Environnements de test et de production}

\begin{itemize}
	\item Des environnements de \textbf{test} et de \textbf{staging} reprenant la même architecture que la production ont été mis en place afin de valider les développements et les mises à jour.
	\item Les environnements de \textbf{production} ont été configurés avec des sauvegardes automatiques et des mesures renforcées de sécurité et de supervision.
	\item Kustomize a ete utilisé pour garder une concistence et de gérer les variations de configuration entre les environnements, permettant de maintenir une base commune tout en adaptant les paramètres spécifiques (par exemple, les ressources allouées, les endpoints externes, etc.).
\end{itemize}

\subsection{Intégration et automatisation des déploiements}

\textbf{GitLab CI/CD} joue un rôle central dans l'automatisation du cycle de vie applicatif. L’ensemble du pipeline est défini dans le fichier \texttt{.gitlab-ci.yml}, qui décrit les différentes étapes à exécuter pour chaque push, merge ou tag selon la configuration définie.

L’infrastructure GitLab repose sur plusieurs composants clés :
\begin{itemize}
	\item \textbf{.gitlab-ci.yml} : fichier principal décrivant les jobs et les stages du pipeline.
	\item \textbf{GitLab Runners} : exécutent les jobs dans des environnements isolés (VMs, containers...).
	\item \textbf{Variables GitLab} : utilisées pour stocker de manière sécurisée les credentials (tokens d’accès, clés API, identifiants, etc.), accessibles dans les jobs via des variables d’environnement.
	\item \textbf{Scripts et templates} : fichiers auxiliaires contenant les commandes d’automatisation (par exemple : \texttt{deploy.sh}, \texttt{test.sh}, \texttt{build.Dockerfile}).
\end{itemize}

\subsection{Structure générale d’un pipeline GitLab CI}

Un pipeline CI/CD complet est généralement structuré autour des étapes suivantes :

\begin{itemize}
	\item \textbf{Validation}
	\item Formatage du code (ex : \texttt{black}, \texttt{prettier}, \texttt{clang-format}).
	\item Tests unitaires et fonctionnels (ex : \texttt{pytest}, \texttt{Jest}, \texttt{JUnit}).
	\item Analyse de dépendances (\texttt{OWASP Dependency-Check}, \texttt{safety}).
	\item Analyse de sécurité des secrets (\texttt{truffleHog}, \texttt{git-secrets}).
	\item Linting et analyse statique (ex : \texttt{ESLint}, \texttt{pylint}, \texttt{SonarQube}).
\end{itemize}

\begin{itemize}
	\item \textbf{Build}
	      \begin{itemize}
		      \item Compilation de binaires ou de librairies.
		      \item Construction d’images Docker avec \texttt{Dockerfile}.
		      \item Intégration des modules ou plugins nécessaires.
	      \end{itemize}
	\item \textbf{Package}
	      \begin{itemize}
		      \item Génération des artefacts (archives, packages, images).
		      \item Génération automatique de changelogs (\texttt{git-chglog}, \texttt{conventional-changelog}).
		      \item Mise à jour du \texttt{README}, documentation ou métadonnées.
	      \end{itemize}
	\item \textbf{Release}
	      \begin{itemize}
		      \item Création d’une release GitLab avec description, tag, et artefacts associés.
		      \item Publication vers des registries (DockerHub, GitLab Container Registry, PyPI, Maven, etc.).
		      \item Possibilité de signature cryptographique des artefacts.
	      \end{itemize}
	\item \textbf{Deploy}
	      \begin{itemize}
		      \item Déploiement automatique vers les environnements cibles (dev, staging, prod).
		      \item Utilisation de \texttt{kubectl}, \texttt{helm}, ou ArgoCD pour interagir avec Kubernetes.
		      \item Authentification via credentials sécurisés définis comme \texttt{CI/CD variables}.
	      \end{itemize}
	\item \textbf{Notify}
	      \begin{itemize}
		      \item Envoi de notifications Slack, Discord, Rocket.Chat, email ou webhook.
		      \item Génération de rapports HTML ou PDF avec les résultats des tests et des déploiements.
		      \item Archivage des logs dans des systèmes de monitoring (ELK, Loki, etc.).
	      \end{itemize}
\end{itemize}

\subsection{Exemple de gestion des credentials}
Les variables sensibles telles que les clés d’accès API, tokens d'acces aux depots et tokens de déploiement ou credentials Kubernetes sont définies dans l’interface GitLab CI/CD (\texttt{Settings > CI/CD > Variables}) et injectées dans les jobs via :
\begin{verbatim}
deploy:
script:
- echo "$KUBECONFIG_SECRET" > kubeconfig
- kubectl --kubeconfig=kubeconfig apply -f k8s/
\end{verbatim}

\subsection{Exemple de stage de release}
\begin{verbatim}
release:
stage: release
script:
- echo "Generating release..."
- git tag v${CI_COMMIT_SHORT_SHA}
- git push origin v${CI_COMMIT_SHORT_SHA}
- curl --header "PRIVATE-TOKEN: $GITLAB_TOKEN"
--data "name=Release v${CI_COMMIT_SHORT_SHA}&tag_name=v${CI_COMMIT_SHORT_SHA}"
"https://gitlab.com/api/v4/projects/${CI_PROJECT_ID}/releases"
\end{verbatim}

% Schéma GitLab CI
\begin{figure}[H]
	\centering
	\includegraphics[width=0.85\textwidth]{figures/gitlab-ci.png}
	\caption{Processus d'intégration et de déploiement continu}
\end{figure}

\section{Fondements théoriques de l’automatisation des infrastructures}

\subsection{Évolution historique}

La gestion des systèmes d’information a connu une évolution rapide, marquée par plusieurs transformations majeures. Elle est passée de l’administration manuelle des serveurs physiques, où chaque déploiement nécessitait des opérations répétitives et susceptibles d’erreurs, à l’émergence des datacenters virtualisés et du Cloud Computing. Cette progression a été motivée par la recherche d’une meilleure agilité opérationnelle et par la nécessité de réduire les coûts d’exploitation.

La complexification des environnements informatiques a conduit à la formalisation de pratiques visant à automatiser la création, la configuration et la supervision des ressources. C’est dans ce contexte qu’a émergé le paradigme de l’Infrastructure as Code, qui constitue aujourd’hui un socle incontournable des démarches de modernisation.

\subsection{Approche DevOps}

Le développement des infrastructures modernes s’inscrit dans une démarche DevOps, qui associe les équipes de développement et d’exploitation dans une collaboration continue. Cette approche vise à réduire les cycles de livraison, améliorer la qualité logicielle et favoriser l’automatisation des processus. Elle s’appuie sur une culture de responsabilisation partagée, une intégration continue et une surveillance permanente des systèmes. DevOps contribue ainsi à faire converger les objectifs techniques et organisationnels, en alignant la production logicielle et les opérations.

\begin{figure} [H]
	\centering
	\includegraphics[width=.5\textwidth]{figures/Devops.png}
	\caption{Taches de DevOps}
\end{figure}
\subsection{Modèles conceptuels}

L’Infrastructure as Code (IaC) désigne l’ensemble des méthodes et outils permettant de décrire l’état souhaité d’une infrastructure sous forme de fichiers de configuration versionnés et exécutables. Deux modèles se distinguent généralement : le modèle impératif, dans lequel l’utilisateur décrit la séquence exacte des opérations, et le modèle déclaratif, qui se concentre sur la définition de l’état final visé en laissant au moteur d’exécution la responsabilité d’y converger.

\subsection{Approche GitOps}

En prolongement de l’IaC, l’approche GitOps propose de faire du système de gestion de version la source unique de vérité pour la configuration et le déploiement applicatif. Elle se caractérise par un processus de déploiement automatisé, piloté par des agents qui observent l’état déclaré dans les dépôts et appliquent les modifications nécessaires aux environnements. Cette méthode garantit une traçabilité complète des évolutions, facilite le retour en arrière et renforce la cohérence entre les différents environnements. GitOps s’intègre naturellement avec les pipelines CI/CD, qui orchestrent la construction, les tests et la mise en production de façon systématique.

\section{Conteneurisation et orchestration}

\subsection{Principes de la conteneurisation}

La conteneurisation a constitué une rupture technologique majeure en introduisant une isolation légère des environnements d’exécution, en comparaison avec les machines virtuelles traditionnelles. Chaque conteneur encapsule l’application et ses dépendances, assurant ainsi une portabilité élevée et une reproductibilité des exécutions sur différents environnements.Selon une étude de la CNCF et le rapport State of Containers de Datadog, plus de 80 \% des entreprises utilisant des microservices ont adopté des conteneurs dans leur environnement de production. En 2022, la CNCF rapportait que 42 \% des organisations exécutaient plus de 50 \% de leurs workloads en conteneurs, une proportion qui ne cesse de progresser.Parmi les bénéfices les plus fréquemment identifiés figurent la réduction de la charge système (les conteneurs consomment en moyenne 30 à 50 \% moins de ressources que des machines virtuelles équivalentes), l’optimisation des coûts d’infrastructure, l’accélération des cycles de déploiement (près de 60 \% des entreprises déclarent qu’elles déploient des applications en production plusieurs fois par semaine grâce aux conteneurs) et une meilleure isolation des processus.

\subsection{Orchestration des conteneurs}

Pour coordonner ces conteneurs à grande échelle, des plateformes d’orchestration ont été développées. Kubernetes s’est progressivement imposé comme la solution de référence, grâce à sa capacité à automatiser le placement des workloads, l’ajustement dynamique des ressources, la relance des conteneurs défaillants et la gestion centralisée des configurations ainsi que des secrets.Selon le rapport annuel de la Cloud Native Computing Foundation (CNCF), Kubernetes est aujourd’hui utilisé par plus de 96 \% des organisations qui exploitent des conteneurs en production. Sa popularité ne cesse de croître : en 2016, seuls 27 \% des répondants déclaraient l’utiliser, contre près de 90 \% en 2022, ce qui illustre l’ampleur de son adoption. Ces fonctionnalités favorisent l’exploitation efficace d’environnements complexes et distribués. De plus, plus de 70 \% des entreprises déclarent que Kubernetes joue un rôle stratégique dans leur modernisation applicative et l’adoption du cloud hybride.

\subsection{Patterns d’architecture cloud-native}

La conteneurisation et l’orchestration encouragent l’adoption de modèles applicatifs dits \emph{cloud-native}. Ces architectures reposent notamment sur le découpage en microservices, la scalabilité horizontale, la résilience par la redondance et le découplage entre l’infrastructure et les applications. Ces principes sont aujourd’hui largement adoptés par les entreprises souhaitant moderniser leurs systèmes d’information.

\section{Approches de supervision et d’observabilité}

\subsection{Enjeux de l’observabilité}

Dans des environnements distribués et dynamiques, l’observabilité est un facteur déterminant de fiabilité et de performance. Elle va au-delà de la supervision traditionnelle en visant une compréhension globale et en temps réel des comportements des systèmes. Cette démarche repose sur trois piliers essentiels : les métriques, qui mesurent l’état et les performances ; les logs, qui conservent l’historique des événements ; et les traces distribuées, qui permettent de suivre le parcours des requêtes au sein de l’architecture.

\subsection{Outils et standards de référence}

Différentes solutions se sont imposées comme standards de fait dans le domaine. Prometheus est souvent privilégié pour la collecte des métriques et la génération d’alertes, tandis que Grafana assure leur visualisation et leur suivi en temps réel. Elastic Stack ou Loki sont fréquemment utilisés pour l’agrégation et l’analyse des logs, et des outils tels que Jaeger et OpenTelemetry facilitent le traçage distribué. L’adoption de protocoles ouverts et d’API standardisées favorise leur intégration avec les plateformes d’orchestration.

\section{Sécurité des infrastructures automatisées}

\subsection{Principes de sécurité}

La sécurisation des infrastructures automatisées s’appuie sur le principe de \emph{Security by Design}, qui préconise l’intégration des mesures de protection dès les phases initiales de conception. Le modèle \emph{Zero Trust}, largement diffusé, repose notamment sur l’absence de confiance implicite accordée à un composant, l'identification, l’authentification et l’autorisation systématiques de chaque requête ainsi que la limitation des privilèges au strict nécessaire. Ces approches sont particulièrement adaptées aux environnements hybrides et multi-clouds.

\subsection{Gestion des secrets et des accès}

La gestion centralisée des secrets constitue une pratique essentielle pour sécuriser les identifiants, certificats et autres éléments sensibles. Elle repose sur le stockage chiffré, la rotation périodique des clés et la traçabilité des accès. Des outils spécialisés, tels que Vault, apportent des solutions robustes et éprouvées pour répondre à ces exigences.

\subsection{Sécurité périmétrique et segmentation}

La protection des infrastructures repose également sur des dispositifs périmétriques tels que les pare-feu, les listes de contrôle d’accès et la segmentation réseau. Ces mécanismes permettent de limiter la surface d’exposition, de cloisonner les environnements et de renforcer la résilience face aux attaques latérales. La mise en œuvre de politiques de filtrage strictes et le principe du moindre privilège complètent ces mesures pour réduire les risques d’intrusion.

\subsection{Option : pfSense en tant que routeur et pare-feu principal}

Dans l’architecture retenue, il est possible de déployer pfSense comme machine virtuelle dédiée assurant le rôle de passerelle unique et de point de contrôle des flux réseau. Dans ce scénario, pfSense est connecté à deux interfaces réseau distinctes :

\begin{itemize}
	\item Une interface \textbf{LAN}, reliée au réseau interne Proxmox et aux machines virtuelles.
	\item Une interface \textbf{WAN}, reliée au réseau externe (Internet).
\end{itemize}

Toutes les machines virtuelles définissent pfSense comme leur passerelle par défaut. Cela permet :

\begin{itemize}
	\item De centraliser le filtrage et le NAT.
	\item De contrôler et journaliser l’ensemble des flux entrants et sortants.
	\item D’appliquer des politiques de segmentation et de routage spécifiques par VLAN ou sous-réseau.
	\item D’établir des tunnels VPN (IPSec, OpenVPN) de manière centralisée.
\end{itemize}

Cette approche offre une séparation claire entre le plan de gestion (Proxmox) et le plan de données (trafic applicatif), améliorant la sécurité globale.

\begin{figure}[H]
	\centering
	\begin{tikzpicture}[
			node distance=2cm,
			box/.style={draw, rectangle, minimum width=3cm, minimum height=1cm, align=center},
			vm/.style={draw, rectangle, minimum width=2cm, minimum height=0.8cm, align=center}
		]
		% Nodes
		\node[box] (internet) {Internet};
		\node[box, below of=internet] (proxmox) {Proxmox Hyperviseur};
		\node[box, below of=proxmox] (pfsense) {VM pfSense \\ (Pare-feu / Routeur)};
		\node[box, below of=pfsense] (switch) {Réseau LAN Interne};
		\node[vm, left=1.5cm of switch] (vm1) {VM1};
		\node[vm, right=1.5cm of switch] (vm2) {VM2};
		% Arrows
		\draw[->] (internet) -- (proxmox);
		\draw[->] (proxmox) -- (pfsense);
		\draw[->] (pfsense) -- (switch);
		\draw[->] (switch) -- (vm1);
		\draw[->] (switch) -- (vm2);
	\end{tikzpicture}
	\caption{Architecture avec pfSense en tant que routeur et pare-feu principal}
\end{figure}

Cette configuration permet de garantir que tout le trafic réseau transite par pfSense, offrant un contrôle périmétrique complet et la possibilité d’appliquer des politiques de sécurité avancées.

\subsection{Réplication et résilience}

La réplication et la résilience constituent des aspects essentiels de l’infrastructure mise en place, afin de garantir la haute disponibilité des services et la continuité des opérations en cas d’incident.

\paragraph{Virtualisation et clustering Proxmox}
Au niveau de la virtualisation, un cluster Proxmox a été configuré avec plusieurs nœuds physiques interconnectés, permettant de mutualiser les ressources et de répartir les charges de travail. Plusieurs approches existent pour assurer la continuité de service en cas de défaillance matérielle :

\begin{itemize}
	\item \textbf{Réplication manuelle des machines virtuelles}, qui consiste à effectuer périodiquement des copies complètes des disques virtuels sur un autre hôte. Cette approche présente l’avantage d’être simple à mettre en place, mais elle implique des délais de récupération plus longs, car il faut importer et redémarrer la VM sur un autre nœud après une panne.
	\item \textbf{Réplication programmée via Proxmox}, qui offre la possibilité de définir des règles de réplication asynchrone (par exemple toutes les 15 minutes) vers un nœud cible. En cas d’incident, la VM peut être démarrée rapidement sur l’hôte de secours à partir du dernier état synchronisé. Cette approche réduit considérablement le RTO (Recovery Time Objective), tout en restant plus simple à opérer que des solutions de stockage distribuées.
	\item \textbf{Stockage distribué Ceph}, qui permet de disposer d’un volume partagé entre tous les nœuds du cluster, avec réplication synchrone des données et tolérance aux pannes disque et hôte. Cette solution est plus complexe à déployer et nécessite un minimum de trois nœuds, mais elle offre un haut niveau de résilience et la possibilité de migrer dynamiquement les VM sans interruption.
\end{itemize}

Le cluster en place privilégie une approche combinant la réplication programmée pour les VM critiques et un stockage partagé Ceph pour les ressources nécessitant un très haut niveau de disponibilité.

\paragraph{Sauvegarde des données}
La sauvegarde des données est assurée par Proxmox Backup Server, qui permet d’effectuer des sauvegardes incrémentielles planifiées et chiffrées des machines virtuelles et des conteneurs. Contrairement à une simple réplication, la sauvegarde conserve un historique versionné, facilitant la restauration en cas de corruption de données ou d’erreur humaine. Les sauvegardes sont stockées sur un volume dédié, avec vérification d’intégrité et possibilités de restauration granulaire.

\paragraph{Stockage persistant dans Kubernetes}
En complément de la virtualisation, le stockage des volumes persistants dans l’environnement Kubernetes repose sur Longhorn. Plusieurs options étaient envisageables :
\begin{itemize}
	\item L’utilisation de volumes locaux, plus performants, mais ne permettant pas de réplication automatique entre les nœuds.
	\item Le recours à un stockage NFS externe, qui simplifie la mutualisation mais peut devenir un point unique de défaillance.
	\item L’intégration de solutions distribuées comme Rook-Ceph ou Longhorn, permettant la réplication synchrone des volumes, les snapshots, et la tolérance aux pannes.
\end{itemize}
Longhorn a été retenu pour sa simplicité de mise en œuvre et sa capacité à assurer la résilience des volumes persistants sans dépendance externe, en maintenant automatiquement plusieurs répliques synchronisées sur des nœuds distincts.

\paragraph{Réseau et accès externe}
L’accès aux services exposés à Internet est assuré par un reverse proxy. Plusieurs stratégies sont envisageables :
\begin{itemize}
	\item Héberger le reverse proxy directement sur un des nœuds Proxmox, ce qui simplifie l’architecture mais implique un couplage entre l’hyperviseur et le point d’entrée réseau.
	\item Déployer le reverse proxy dans un cluster Kubernetes, avec des réplicas et des LoadBalancers qui répartissent les connexions.
	\item Séparer le reverse proxy sur des VMs dédiées (ou des serveurs physiques distincts), avec une configuration VRRP (via Keepalived) pour disposer d’une IP virtuelle flottante. En cas de panne d’un nœud, l’IP est automatiquement reprise par l’instance survivante, assurant une continuité de service transparente.
\end{itemize}
Dans l’architecture retenue, le reverse proxy est externalisé sur des VMs dédiées, configurées en haute disponibilité avec Keepalived. Cette séparation garantit que la couche de routage HTTP et HTTPS n’est pas dépendante de l’état des hyperviseurs.

\paragraph{Réplication et résilience applicative}
Concernant les applications elles-mêmes, le cluster Kubernetes est configuré pour exécuter plusieurs réplicas des pods assurant les services critiques. Les déploiements définissent un nombre minimal de réplicas répartis sur des nœuds distincts. Ainsi, la perte d’un hôte n’interrompt pas la disponibilité du service. Les probes de liveness et readiness assurent la surveillance de la santé des instances, permettant leur redémarrage automatique en cas de défaillance logicielle. L’autoscaling horizontal complète le dispositif en ajustant dynamiquement le nombre de réplicas selon la charge.

\paragraph{Comparaison synthétique des approches}
\begin{table}[H]
	\renewcommand{\arraystretch}{1.3}
	\centering
	\begin{tabular}{|p{4cm}|p{5cm}|p{5cm}|}
		\hline
		\textbf{Aspect}                 & \textbf{Approche minimale}               & \textbf{Approche avancée (retenue)}                   \\
		\hline
		Stockage VM                     & Disques locaux avec réplication manuelle & Ceph distribué avec réplication synchrone             \\
		\hline
		Sauvegardes                     & Copie manuelle périodique                & Proxmox Backup Server avec incrémental et chiffrement \\
		\hline
		Reverse proxy                   & Service unique sur un hyperviseur        & VMs dédiées + Keepalived avec IP flottante            \\
		\hline
		Volumes Kubernetes              & Volumes locaux/NFS simple                & Longhorn avec répliques synchrones et snapshots       \\
		\hline
		Haute disponibilité VMs         & Migration manuelle après panne           & HA Proxmox avec redémarrage automatique               \\
		\hline
		Haute disponibilité applicative & Un seul pod sans réplication             & Réplicas multiples et autoscaling                     \\
		\hline
	\end{tabular}
	\caption{Comparaison des options de réplication et résilience}
\end{table}

L’ensemble de ces mesures contribue à renforcer la tolérance aux pannes de l’infrastructure, en combinant la redondance au niveau des ressources physiques, la réplication des données et la résilience logicielle des applications.

\subsection{Distribution du réseau}

La distribution du réseau constitue un fondement essentiel de l’architecture moderne, permettant d’assurer la scalabilité, la tolérance aux pannes et la performance des services.

\paragraph{Segmentation et isolation}
Afin de garantir la sécurité et l’isolation des flux, l’infrastructure est segmentée en plusieurs sous-réseaux virtuels (VLAN) :
\begin{itemize}
	\item Un réseau interne réservé aux communications entre hyperviseurs et au trafic de stockage distribué.
	\item Un réseau de management, isolé des services applicatifs, pour l’administration sécurisée des nœuds.
	\item Un réseau applicatif sur lequel sont exposés les pods Kubernetes et les services internes.
	\item Un réseau public dédié à la publication des applications via le reverse proxy.
\end{itemize}
Cette séparation limite la surface d’attaque et réduit le risque de propagation d’incident.

\paragraph{Haute disponibilité et équilibrage de charge}
Plusieurs stratégies existent pour distribuer le trafic :
\begin{itemize}
	\item \textbf{Approche monolithique}, reposant sur un seul point d’entrée réseau (reverse proxy unique), plus simple mais vulnérable en cas de défaillance.
	\item \textbf{Approche active-passive} avec VRRP (Keepalived), qui met en place une IP flottante basculant automatiquement entre deux nœuds en cas de panne.
	\item \textbf{Approche active-active}, consistant à disposer de plusieurs points d’entrée en équilibrage de charge, avec synchronisation des configurations (par exemple HAProxy + Consul Template). Cette approche offre une scalabilité horizontale et une meilleure tolérance aux pannes.
\end{itemize}
L’infrastructure mise en place adopte une combinaison d’un cluster de reverse proxies déployés sur des VMs dédiées et d’un mécanisme VRRP assurant la continuité de l’adresse IP publique.

\paragraph{Routage interne et service discovery}
Les communications entre microservices dans Kubernetes sont gérées via le DNS interne CoreDNS, qui résout automatiquement les noms des services et assure la découverte dynamique. Pour certaines applications nécessitant une tolérance accrue, un service mesh (comme Istio ou Linkerd) peut être ajouté afin d’enrichir le routage, la sécurité mutuelle (mTLS) et la résilience (circuit breaking).

\paragraph{Comparaison des approches}
\begin{table}[H]
	\renewcommand{\arraystretch}{1.3}
	\centering
	\begin{tabular}{|p{4cm}|p{5cm}|p{5cm}|}
		\hline
		\textbf{Aspect}        & \textbf{Approche simple} & \textbf{Approche distribuée avancée} \\
		\hline
		Points d’entrée réseau & Reverse proxy unique     & Plusieurs reverse proxies actifs     \\
		\hline
		Haute disponibilité IP & Non, dépend du nœud      & VRRP avec IP flottante               \\
		\hline
		Service discovery      & Résolution DNS simple    & Service mesh avec routage avancé     \\
		\hline
		Isolation des flux     & VLAN minimal             & Segmentation stricte par rôle        \\
		\hline
	\end{tabular}
	\caption{Comparaison des stratégies de distribution réseau}
\end{table}

L’ensemble de cette configuration permet d’assurer un routage robuste et un point d’entrée tolérant aux pannes pour l’ensemble des services.

\subsection{Distribution du traitement}

La distribution du traitement vise à découpler l’exécution des charges de travail sur plusieurs ressources matérielles et logicielles, afin d’optimiser la disponibilité et la scalabilité.

\paragraph{Virtualisation et orchestration}
Le cluster Proxmox offre la première couche de distribution, en permettant de répartir les VM et conteneurs sur plusieurs hyperviseurs. Les ressources CPU et mémoire peuvent être ajustées dynamiquement par migration des charges (Live Migration), ce qui autorise des opérations de maintenance sans interruption.

Au-dessus de cette couche, Kubernetes orchestre les applications conteneurisées en multipliant les réplicas des pods sur les nœuds disponibles. Chaque déploiement spécifie :
\begin{itemize}
	\item Le nombre minimal et maximal de réplicas.
	\item Les contraintes d’affinité (anti-affinity) garantissant leur répartition sur différents hôtes physiques.
	\item Les ressources CPU/mémoire réservées et limites pour chaque pod.
\end{itemize}
Cette stratégie permet d’assurer la continuité du service même lors de la perte d’un nœud.

\paragraph{Autoscaling et gestion de la charge}
Plusieurs mécanismes de scaling sont mis en place :
\begin{itemize}
	\item \textbf{Horizontal Pod Autoscaler (HPA)} qui ajuste dynamiquement le nombre de réplicas en fonction de la consommation CPU ou des métriques personnalisées.
	\item \textbf{Vertical Pod Autoscaler (VPA)} qui ajuste automatiquement les ressources allouées à chaque pod.
	\item \textbf{Cluster Autoscaler}, qui peut provisionner de nouveaux nœuds si la capacité devient insuffisante.
\end{itemize}
Dans un contexte haute disponibilité, ces fonctionnalités garantissent une adaptation continue à la charge, tout en conservant une redondance suffisante.

\paragraph{Comparaison des stratégies de traitement}
\begin{table}[H]
	\renewcommand{\arraystretch}{1.3}
	\centering
	\begin{tabular}{|p{4cm}|p{5cm}|p{5cm}|}
		\hline
		\textbf{Aspect}         & \textbf{Approche statique}      & \textbf{Approche dynamique distribuée}              \\
		\hline
		Placement des workloads & Affectation fixe sur un hôte    & Orchestration dynamique par Kubernetes              \\
		\hline
		Scalabilité             & Manuelle                        & Autoscaling horizontal et vertical                  \\
		\hline
		Disponibilité           & Réplication minimale ou absente & Réplicas multiples avec anti-affinité               \\
		\hline
		Maintenance             & Arrêt manuel des VM             & Migration transparente et redéploiement automatique \\
		\hline
	\end{tabular}
	\caption{Comparaison des approches de distribution du traitement}
\end{table}

Cette distribution automatisée du traitement garantit une meilleure résilience face aux pannes et une adaptation continue à la demande.

\subsection{Distribution du stockage}

La distribution du stockage vise à assurer la durabilité, la performance et la disponibilité des données, en s’appuyant sur des mécanismes de réplication et de tolérance aux pannes.

\paragraph{Stockage des disques virtuels}
Pour les machines virtuelles, plusieurs options ont été étudiées :
\begin{itemize}
	\item \textbf{Stockage local} : chaque hôte stocke les disques sur un volume interne (SSD ou HDD). Simple à configurer, cette approche présente un risque élevé de perte en cas de panne.
	\item \textbf{Stockage NFS partagé} : un serveur central héberge les disques. Ce modèle simplifie le partage mais devient un point unique de défaillance.
	\item \textbf{Stockage Ceph distribué} : tous les nœuds participent au stockage, avec réplication automatique des blocs et rebalancing dynamique en cas de panne d’un disque ou d’un hôte.
\end{itemize}
L’architecture privilégie Ceph, qui offre un bon compromis entre performance, redondance et évolutivité.

\paragraph{Stockage des volumes Kubernetes}
Pour les applications conteneurisées, Longhorn a été choisi :
\begin{itemize}
	\item Chaque volume est répliqué en temps réel sur plusieurs nœuds.
	\item Les snapshots incrémentaux permettent des restaurations rapides.
	\item Le système de scheduling des réplicas garantit leur distribution sur des hôtes distincts.
\end{itemize}
Cette approche élimine les points de défaillance uniques et simplifie la gestion des volumes persistants.

\paragraph{Sauvegarde et archivage}
La sauvegarde des données est assurée par un système multi-niveaux :
\begin{itemize}
	\item \textbf{Snapshots Ceph et Longhorn}, pour des points de restauration rapides.
	\item \textbf{Sauvegardes incrémentielles chiffrées via Proxmox Backup Server}, permettant un stockage historique et une restauration granulaire.
	\item \textbf{Archivage distant}, avec synchronisation vers un dépôt externe pour protéger contre les sinistres majeurs.
\end{itemize}

\paragraph{Comparaison des approches de stockage}
\begin{table}[H]
	\renewcommand{\arraystretch}{1.3}
	\centering
	\begin{tabular}{|p{4cm}|p{5cm}|p{5cm}|}
		\hline
		\textbf{Aspect}      & \textbf{Approche locale}              & \textbf{Approche distribuée}                     \\
		\hline
		Redondance           & Aucune                                & Réplication synchrone multi-nœuds                \\
		\hline
		Performance          & Locale, rapide                        & Équilibrée selon le réseau et les disques        \\
		\hline
		Tolérance aux pannes & Perte de données si panne disque/nœud & Données conservées malgré plusieurs défaillances \\
		\hline
		Scalabilité          & Capacité limitée par hôte             & Extension linéaire en ajoutant des nœuds         \\
		\hline
	\end{tabular}
	\caption{Comparaison des options de distribution du stockage}
\end{table}

Ces mécanismes contribuent à garantir la sécurité et la continuité des données, en limitant les impacts des défaillances matérielles et logicielles.

\subsection{Sauvegarde et restauration}

La sauvegarde et la restauration des données constituent un pilier central de la stratégie de continuité d’activité. Elles complètent les mécanismes de haute disponibilité et de réplication, en permettant de récupérer des données perdues ou corrompues, y compris en cas d’incidents majeurs (pannes simultanées, erreurs humaines, attaques).

\paragraph{Objectifs et distinction avec la haute disponibilité}
La sauvegarde diffère fondamentalement de la haute disponibilité :
\begin{itemize}
	\item La \textbf{haute disponibilité} (HA) vise à garantir que le service continue de fonctionner sans interruption notable, même en cas de défaillance matérielle ou logicielle, grâce à la redondance et au basculement automatique.
	\item La \textbf{sauvegarde} (backup) vise à conserver une copie historisée des données à un instant donné, indépendamment du fonctionnement du système. Elle permet de revenir en arrière après une corruption, une suppression accidentelle ou une compromission.
\end{itemize}
Ainsi, la haute disponibilité n’élimine pas la nécessité de disposer de sauvegardes fiables : un système HA peut propager une erreur ou une suppression sur tous les nœuds.

\paragraph{Snapshots vs. sauvegardes}
Il est également essentiel de distinguer les \textbf{snapshots} des sauvegardes classiques :
\begin{itemize}
	\item Un \textbf{snapshot} est une image instantanée d’un volume ou d’une machine virtuelle, généralement stockée sur le même système que les données originales. Il permet une restauration rapide mais ne protège pas contre une perte physique du support.
	\item Une \textbf{sauvegarde} est exportée et stockée sur un système séparé, parfois chiffré et versionné. Elle répond au principe fondamental de la règle «3-2-1» (3 copies, sur 2 supports différents, dont 1 hors site).
\end{itemize}
Dans l’infrastructure mise en place, les snapshots Ceph ou Longhorn sont utilisés pour des restaurations rapides, tandis que les sauvegardes incrémentielles Proxmox Backup Server assurent une protection durable et hors site.

\paragraph{Types de sauvegardes}
Plusieurs stratégies de sauvegarde coexistent :

\begin{itemize}
	\item \textbf{Sauvegarde complète} : copie intégrale de toutes les données à chaque exécution. Elle simplifie la restauration mais consomme un espace disque important et augmente la durée des sauvegardes.
	\item \textbf{Sauvegarde différentielle} : copie uniquement les modifications apportées depuis la dernière sauvegarde complète. Lors de la restauration, il suffit de combiner la sauvegarde complète et la dernière différentielle.
	\item \textbf{Sauvegarde incrémentielle} : copie les modifications depuis la dernière sauvegarde (complète ou incrémentielle). Elle minimise l’espace requis et la durée de l’opération, mais la restauration nécessite de rejouer la chaîne complète d’incréments.
\end{itemize}
Proxmox Backup Server repose sur une approche incrémentielle optimisée par déduplication et vérification d’intégrité, offrant un bon compromis entre rapidité et sécurité.

\paragraph{Sauvegarde des machines virtuelles}
Les VM Proxmox sont sauvegardées selon une politique planifiée :
\begin{itemize}
	\item Sauvegarde complète hebdomadaire.
	\item Sauvegarde incrémentielle quotidienne.
	\item Rétention configurée pour conserver plusieurs versions et éviter la saturation du stockage.
\end{itemize}
Chaque sauvegarde est chiffrée, signée et vérifiée par Proxmox Backup Server. Cette granularité permet de restaurer une VM entière ou des fichiers spécifiques.

\paragraph{Sauvegarde des volumes persistants Kubernetes}
Pour Kubernetes, Longhorn offre une gestion avancée des snapshots et sauvegardes :
\begin{itemize}
	\item Les \textbf{snapshots} permettent de capturer un état instantané du volume et de le restaurer localement.
	\item Les \textbf{sauvegardes} Longhorn sont exportées vers un stockage objet (MinIO ou S3), garantissant leur conservation hors du cluster.
\end{itemize}
Ces sauvegardes sont déclenchées automatiquement après certaines opérations critiques et complétées par des sauvegardes applicatives (par exemple, dumps de base de données).

\paragraph{Archivage distant}
Un mécanisme d’archivage complémentaire synchronise périodiquement les sauvegardes vers un dépôt externe géographiquement séparé. Cette mesure protège contre les sinistres majeurs tels qu’un incendie ou un ransomware affectant l’infrastructure principale.

\paragraph{Comparaison des approches}
\begin{table}[H]
	\renewcommand{\arraystretch}{1.3}
	\centering
	\begin{tabular}{|p{4cm}|p{4cm}|p{4cm}|p{4cm}|}
		\hline
		\textbf{Aspect}                  & \textbf{Haute disponibilité}      & \textbf{Snapshot}          & \textbf{Sauvegarde complète/incrémentielle} \\
		\hline
		Objectif principal               & Continuité de service             & Restauration rapide locale & Protection historique et hors site          \\
		\hline
		Périmètre                        & Processus et disponibilité des VM & État instantané du disque  & Copies versionnées des données              \\
		\hline
		Protection contre la corruption  & Non                               & Non (propagée)             & Oui                                         \\
		\hline
		Protection contre perte physique & Non                               & Non                        & Oui                                         \\
		\hline
		Temps de restauration            & Instantané (pas d’interruption)   & Très rapide                & Plus long selon volume                      \\
		\hline
	\end{tabular}
	\caption{Comparaison entre HA, snapshots et sauvegardes}
\end{table}

\paragraph{Synthèse}
En combinant la haute disponibilité, les snapshots rapides et les sauvegardes incrémentielles chiffrées, l’architecture garantit :
\begin{itemize}
	\item La continuité de service face aux pannes matérielles.
	\item La restauration rapide après une corruption.
	\item La conservation historique et l’archivage sécurisé des données critiques.
\end{itemize}
Ces mécanismes sont complémentaires et répondent chacun à des scénarios spécifiques de reprise après incident.

