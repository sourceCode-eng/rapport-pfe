\section{Introduction}

Dans un environnement où les systèmes d'information deviennent de plus en plus complexes et interconnectés, la gestion manuelle des infrastructures techniques pose de nombreux défis. Les entreprises doivent faire face à des exigences croissantes en matière de sécurité, de disponibilité et de performance, tout en cherchant à optimiser leurs coûts et à réduire les délais de mise en production. Cette évolution rend la gestion des infrastructures non seulement complexe, mais parfois inefficace, voire impossible à grande échelle.

Dans ce contexte, l'automatisation des processus d'infrastructure et l'adoption de solutions DevOps sont devenues des priorités stratégiques. La maîtrise de l'infrastructure et des processus de déploiement passe alors d'un luxe à une nécessité afin de soutenir rapidement et efficacement la croissance continue des besoins de l'entreprise.

Cependant, automatiser le déploiement des services ne suffit plus. Il est essentiel de garantir à tout moment leur bon fonctionnement grâce à des mécanismes de supervision et de contrôle rigoureux. La mise en place de solutions de \emph{monitoring}, de \emph{logging} et de \emph{tracing} permet de disposer d'une visibilité complète sur l'état des systèmes, d'anticiper les incidents et de réagir rapidement en cas d'anomalie. Ces dispositifs contribuent également à renforcer la traçabilité et à répondre aux impératifs de conformité réglementaire.

En parallèle, le renforcement de la cybersécurité constitue un enjeu majeur. La multiplication des points d'entrée et l'interconnexion croissante des services exposent l'infrastructure à de nouvelles menaces qu'il convient de prévenir et de détecter de manière proactive.

Ce mémoire s'inscrit dans cette dynamique, avec pour objectif principal de concevoir et mettre en place une solution automatisée, sécurisée et résiliente permettant de déployer, superviser et maintenir l'infrastructure technique de l'entreprise Oneex. Le projet vise à répondre aux besoins opérationnels croissants, à réduire les erreurs manuelles et à garantir un haut niveau de qualité de service et de transparence, tout en respectant les contraintes strictes de sécurité et de conformité réglementaire.

\section{Scénarios de référence et hypothèses de travail}

Dans le cadre de l'étude préalable à la conception d'une solution d'automatisation et de sécurisation des infrastructures, il est pertinent d'envisager un ensemble de scénarios représentatifs susceptibles de se produire dans des environnements techniques comparables. Ces hypothèses permettent d'illustrer les enjeux et de définir les objectifs fonctionnels et opérationnels du projet.

\subsection{Divergences entre environnements}

Il est possible que la configuration manuelle des serveurs, opérée par plusieurs équipes successives, conduise progressivement à des écarts significatifs entre les environnements de développement, de test et de production. Les différences pourraient concerner notamment :
\begin{itemize}
	\item Les versions des systèmes d'exploitation, des librairies et des dépendances logicielles.
	\item Les paramètres réseau tels que l'ouverture de ports ou l'attribution d'adresses IP.
	\item La définition des règles de sécurité (droits d'accès, politiques de pare-feu).
\end{itemize}

Dans un tel scénario, ces divergences pourraient générer des dysfonctionnements applicatifs lors des bascules d'environnement et accroître la difficulté de reproduire les incidents constatés.

\subsection{Gestion hétérogène des secrets}

Un autre scénario plausible concerne l'absence de processus unifié de gestion des informations sensibles (identifiants, clés d'API, certificats). Il est envisageable que ces éléments soient stockés et partagés de façon informelle, par exemple :
\begin{itemize}
	\item Sous forme de fichiers non chiffrés sur les postes individuels.
	\item Par échange de courriels non sécurisés.
	\item Par messagerie instantanée, sans traçabilité ni archivage structuré.
\end{itemize}

Une telle situation serait susceptible d'exposer les infrastructures à des risques accrus de fuite d'informations critiques, ainsi qu'à des difficultés opérationnelles lors des renouvellements ou révocations des secrets.

\subsection{Déficit d'observabilité}

Il est également envisageable qu'une organisation n'ait pas mis en place de dispositif unifié de supervision et de journalisation. Dans ce cas, plusieurs limitations pourraient apparaître :
\begin{itemize}
	\item L'absence de collecte systématique des métriques de performance.
	\item La dispersion des journaux applicatifs sur des serveurs multiples, sans agrégation centralisée.
	\item Le manque de mécanismes de corrélation des événements entre composants.
\end{itemize}

Un tel déficit d'observabilité réduirait la capacité à détecter précocement les anomalies, à diagnostiquer efficacement les causes racines et à mesurer le respect des engagements de qualité de service.

\subsection{Processus de déploiement manuel et long}

Dans un scénario reposant sur un déploiement entièrement manuel, la création d'une infrastructure nouvelle pourrait nécessiter plusieurs jours d'opérations successives :
\begin{enumerate}
	\item Préparation et allocation des ressources matérielles ou virtuelles.
	\item Installation des systèmes d'exploitation et des dépendances logicielles.
	\item Paramétrage des droits d'accès et des configurations de sécurité.
	\item Vérification manuelle de la conformité et du bon fonctionnement des services.
\end{enumerate}

Un tel processus induirait des délais importants, une faible reproductibilité et une exposition accrue aux erreurs humaines.

\subsection{Risques opérationnels associés}

Ces hypothèses convergent vers un ensemble de risques potentiels, parmi lesquels :
\begin{itemize}
	\item L'allongement des délais de livraison et la perte d'agilité opérationnelle.
	\item L'augmentation de la probabilité d'erreurs de configuration.
	\item La difficulté de garantir la sécurité des environnements et la confidentialité des données sensibles.
	\item L'impossibilité de disposer d'une vision globale et en temps réel de l'état de l'infrastructure.
\end{itemize}

Ces risques soulignent l'intérêt d'intégrer, dès la conception de la solution, des mécanismes de \emph{monitoring}, de \emph{logging} et de \emph{tracing}, afin de renforcer la transparence et la capacité de réaction face aux incidents.

\subsection{Justification des orientations retenues}

L'analyse de ces scénarios de référence et des risques associés conduit à considérer comme prioritaire la mise en place d'une démarche structurée autour des axes suivants :
\begin{itemize}
	\item L'automatisation des processus de déploiement et de configuration, afin de réduire les délais et d'améliorer la cohérence.
	\item La centralisation et la sécurisation de la gestion des secrets et des accès, pour prévenir les fuites d'informations sensibles.
	\item Lorsque cela est possible, l'utilisation de mécanismes de génération et de rotation automatique de secrets temporaires (par exemple des credentials ou des clés TLS via des solutions de type \emph{Vault}), afin de limiter l'exposition prolongée des informations d'authentification.
	\item La mise en place d'une gestion stricte des droits d'accès, fondée sur le principe du moindre privilège et l'application des bonnes pratiques du \emph{Zero Trust}, pour réduire la surface d'attaque et contrôler finement les autorisations.
	\item L'intégration d'outils d'observabilité pour assurer un suivi continu et une traçabilité complète des opérations.
	\item Le renforcement des contrôles de sécurité et la conformité avec les normes en vigueur.
\end{itemize}

Ces orientations constituent le socle sur lequel s'appuie le projet présenté dans ce mémoire.

\section{Les besoins fonctionnels}

Les besoins fonctionnels décrivent l'ensemble des fonctionnalités attendues de la solution envisagée, ainsi que les objectifs opérationnels qui en découlent. Ils visent à garantir la cohérence, la sécurité, la traçabilité et la résilience de l'infrastructure et des applications. Ces besoins peuvent être regroupés autour de plusieurs axes principaux :

\subsection*{Provisioning et configuration des ressources}

\begin{itemize}
	\item \textbf{Automatisation du provisioning des ressources} : permettre la création, la configuration et la suppression des composants d'infrastructure de manière déclarative et reproductible, afin de réduire les délais et d'éviter les interventions manuelles.

	\item \textbf{Gestion centralisée et cohérente des configurations} : mettre en œuvre un mécanisme d'orchestration permettant d'installer les dépendances logicielles, d'appliquer les paramétrages requis et de maintenir l'uniformité entre les différents environnements.
\end{itemize}

\subsection*{Déploiement et mise à jour des applications}

\begin{itemize}
	\item \textbf{Déploiement applicatif automatisé et contrôlé} : intégrer un processus déclenchant les déploiements depuis des référentiels versionnés et assurant la synchronisation permanente entre le code source et les environnements cibles.
\end{itemize}

\subsection*{Supervision et observabilité}

\begin{itemize}
	\item \textbf{Supervision proactive et alertes en temps réel} : disposer d'un système de surveillance permettant de collecter les métriques de performance, de visualiser l'état des services et de générer des alertes en cas d'incident.

	\item \textbf{Détection précoce des anomalies} : mettre en place des mécanismes d'analyse continue et d'identification des écarts de comportement afin d'anticiper les incidents et de réduire leur impact.

	\item \textbf{Journalisation centralisée} : assurer la collecte, le stockage et la consultation unifiée des journaux système et applicatifs.
\end{itemize}

\subsection*{Sécurité et gestion des accès}

\begin{itemize}
	\item \textbf{Gestion sécurisée et dynamique des secrets} : intégrer un système centralisé de stockage, de chiffrement et de distribution des informations sensibles, avec des mécanismes de rotation automatique et de durée de vie limitée des secrets lorsque cela est possible.

	\item \textbf{Séparation stricte des environnements} : organiser l'infrastructure en environnements distincts (développement, test, pré-production, production) afin de garantir leur isolation et de limiter les risques de contamination croisée.
\end{itemize}

\subsection*{Résilience et continuité de service}

\begin{itemize}
	\item \textbf{Correction automatique des incidents et des défaillances} : prévoir des processus d'auto-remédiation capables de restaurer l'état nominal des services, par exemple par le redémarrage ou le reprovisionnement automatisé des ressources en cas de panne.
\end{itemize}

\subsection*{Interface de pilotage}

\begin{itemize}
	\item \textbf{Interface unifiée d'administration} : proposer une interface utilisateur et/ou une API permettant d'interagir avec la plateforme de manière sécurisée et traçable.
\end{itemize}

Ces besoins fonctionnels constituent la base de la solution à concevoir, en intégrant les outils et les pratiques DevOps adaptés pour répondre aux enjeux opérationnels et réglementaires de l'entreprise.

\section{Les besoins non fonctionnels}

Les besoins non fonctionnels définissent les critères de qualité, de performance, de sécurité et de conformité que la solution doit respecter de manière transversale. Ces exigences sont essentielles pour garantir la fiabilité, la pérennité et la valeur ajoutée de la plateforme. Elles peuvent être regroupées selon plusieurs dimensions complémentaires.

\subsection*{Qualité de service et performance}

\begin{itemize}
	\item \textbf{Haute disponibilité} : garantir un taux de disponibilité supérieur à 99,9\,\% pour les services critiques, en prévoyant des mécanismes de redondance, de bascule automatique et de tolérance aux pannes.

	\item \textbf{Performance} : assurer des temps de réponse optimaux et constants, y compris en période de forte charge, afin de préserver la qualité d'expérience des utilisateurs et le respect des engagements contractuels (SLA).

	\item \textbf{Scalabilité} : permettre une montée en charge fluide et progressive de l'infrastructure, que ce soit en termes de volume de données, de nombre d'utilisateurs ou de capacités de traitement.

	\item \textbf{Réduction du temps de mise en production} : optimiser les processus afin de diminuer significativement les délais nécessaires au déploiement de nouvelles fonctionnalités ou de correctifs.
\end{itemize}

\subsection*{Sécurité et protection des données}

\begin{itemize}
	\item \textbf{Sécurité renforcée} : garantir la protection des données sensibles, la confidentialité des échanges et la résilience face aux attaques, en appliquant les principes de \emph{security by design} et en intégrant les contrôles de sécurité dès la conception.

	\item \textbf{Gestion stricte des droits d'accès} : appliquer le principe du moindre privilège, segmenter les privilèges et mettre en œuvre des mécanismes de contrôle d'accès granulaires et auditables, conformément aux approches de type Zero Trust.

	\item \textbf{Traçabilité et auditabilité} : conserver un historique détaillé, horodaté et inviolable de toutes les opérations critiques, des changements de configuration et des actions administratives.

	\item \textbf{Audits automatiques de conformité et d'intégrité} : générer périodiquement des rapports permettant de vérifier la cohérence des configurations, la robustesse des mécanismes de sécurité et le respect des politiques internes et réglementaires.
\end{itemize}

\subsection*{Évolutivité et maintenabilité}

\begin{itemize}
	\item \textbf{Maintenabilité} : faciliter l'application des mises à jour logicielles, l'évolution des configurations et l'intégration de nouvelles fonctionnalités, tout en minimisant les interruptions de service.

	\item \textbf{Source unique de vérité (Single Source of Truth)} : centraliser et versionner l'ensemble des configurations, des états d'infrastructure et de la documentation technique dans un référentiel unique, fiable et auditable.
\end{itemize}

\subsection*{Conformité réglementaire et normes applicables}

\begin{itemize}
	\item \textbf{Conformité réglementaire} : respecter les obligations légales et les standards sectoriels en vigueur (RGPD, ISO 27001, NIS2, etc.), ainsi que les exigences spécifiques à l'activité et aux données traitées.
\end{itemize}

% \section{Le deroulement du projet}

% Le projet de mise en place d'une infrastructure automatisée s'est déroulé sur plusieurs mois, en parallèle des activités opérationnelles de l'entreprise. Il s'inscrivait dans une démarche progressive, visant à moderniser les outils et à fiabiliser les processus de déploiement et d'exploitation. Plusieurs contraintes ont dû être prises en compte, notamment la compatibilité avec l'existant, la disponibilité continue des services et la nécessité d'assurer un haut niveau de sécurité. Le planning général a été structuré en phases : conception, mise en œuvre, validation et transfert de compétences.

% \section{Objectifs du projet}

% Les objectifs principaux du projet étaient les suivants :

% \begin{itemize}
%   \item Automatiser le provisioning de l'infrastructure afin de réduire les délais de déploiement.
%   \item Centraliser et sécuriser la gestion des configurations et des secrets.
%   \item Améliorer la supervision et l'observabilité des services.
%   \item Mettre en place une approche GitOps pour les déploiements applicatifs.
%   \item Renforcer la sécurité des accès et des flux réseau.
%   \item Disposer d'environnements distincts (test, staging, production) alignés sur les bonnes pratiques DevOps.
% \end{itemize}

% Ces objectifs contribuent à la fiabilisation des opérations et à la création d'une base technique évolutive et maintenable.

\section{Architecture du projet}

L'architecture globale repose sur une infrastructure virtualisée sous Proxmox, pilotée par Terraform et configurée par Ansible. Kubernetes assure l'orchestration des conteneurs, tandis que des solutions complémentaires (Vault, Grafana, Prometheus, Loki, Tempo, Longhorn, Argo CD) viennent couvrir les besoins en sécurité, stockage et supervision.

	% Si souhaité, tu peux ajouter un schéma ici :
	%\begin{figure}[H]
	%    \centering
	%    \includegraphics[width=0.9\textwidth]{figures/architecture.png}
	%    \caption{Schéma d'architecture globale}
	%\end{figure}

	{Infrastructure as Code avec Terraform}

Terraform a été utilisé pour décrire et provisionner toute l'infrastructure. Les ressources suivantes ont été créées de façon automatisée :

\begin{itemize}
	\item Les machines virtuelles sous Proxmox (masters et workers Kubernetes, serveurs utilitaires).
	\item Les réseaux virtuels et les volumes de stockage.
	\item Les configurations initiales des systèmes (cloud-init).
\end{itemize}

Les modules Terraform ont été organisés de manière modulaire afin de pouvoir réutiliser et adapter la configuration facilement.

	{Configuration automatique avec Ansible}

Ansible a permis de configurer les serveurs après leur création. Des rôles dédiés ont été développés pour :

\begin{itemize}
	\item Installer Kubernetes (RKE2) sur les nœuds.
	\item Déployer les outils de monitoring.
	\item Configurer Vault et Consul.
	\item Appliquer les règles de sécurité et les configurations système.
\end{itemize}

Cette approche garantit une configuration homogène et reproductible.

	{GitOps avec Argo CD}

Argo CD a été mis en place pour gérer les déploiements applicatifs de manière GitOps. Chaque modification des manifestes Kubernetes dans le dépôt Git est automatiquement synchronisée avec le cluster. Cette pratique permet de disposer d’un historique complet des changements et de simplifier les rollbacks en cas de problème.

{Monitoring et observabilité avec Grafana, Prometheus, Loki et Tempo}

Le monitoring s’appuie sur Prometheus pour la collecte des métriques et Grafana pour la visualisation. Loki centralise les logs applicatifs et systèmes, tandis que Tempo gère les traces distribuées. L’ensemble forme une stack cohérente permettant d’assurer la supervision et le diagnostic des incidents.

	{Stockage distribué avec Longhorn}

Longhorn a été déployé comme solution de stockage distribué pour Kubernetes. Il fournit un stockage persistant, tolérant aux pannes, avec des fonctionnalités de snapshot et de restauration.

	{Gestion des secrets avec Vault}

Vault est utilisé comme coffre-fort centralisé pour la gestion des secrets. Il permet de stocker et de distribuer les mots de passe, tokens et certificats de manière sécurisée. Des politiques de contrôle d’accès ont été configurées pour limiter l’exposition des informations sensibles.

	{Mise en place de services internes}

Plusieurs services internes ont été installés pour répondre aux besoins quotidiens des équipes :

\begin{itemize}
	\item GitLab pour la gestion des dépôts et de l’intégration continue.
	\item Harbor comme registre privé de conteneurs.
	\item YouTrack pour le suivi des tâches et incidents.
	\item Nextcloud pour le partage sécurisé de fichiers.
\end{itemize}

Ces outils sont hébergés dans l’infrastructure Kubernetes.

	{Sécurité et gestion de pare-feu avec pfSense}

La sécurité périmétrique repose sur un pare-feu pfSense. Des règles de filtrage ont été définies pour contrôler les flux entrants et sortants, ainsi qu’un VPN pour les accès administratifs. Des mesures de surveillance des connexions ont également été mises en place.

	{Mise en place des services de test et de staging}

Des environnements spécifiques ont été créés pour permettre la validation des développements avant leur mise en production. Ces environnements reprennent l’architecture de production, facilitant les tests de montée en charge et les scénarios de validation.

	{Mise en place de la CI/CD avec GitLab CI}

GitLab CI a été configuré pour automatiser les étapes de build, test et déploiement des applications. Des pipelines ont été créés pour assurer la qualité du code et le déploiement vers les environnements Kubernetes.

	{Mise en place des services de production pour les clients}

Enfin, les environnements de production ont été finalisés et validés en respectant les exigences de performance et de sécurité. La mise en service a inclus la configuration des sauvegardes, la documentation des procédures et la formation des utilisateurs.

\section{Conclusion}
Ce projet de mise en place d'une infrastructure automatisée et sécurisée pour Oneex a permis de répondre aux enjeux opérationnels et stratégiques de l'entreprise. En intégrant des outils modernes et des pratiques DevOps, il a été possible d'améliorer la fiabilité, la sécurité et la rapidité des déploiements.
L'architecture mise en place offre une base solide pour l'évolution future des services, tout en
assurant une gestion centralisée et sécurisée des configurations et des secrets. Les équipes disposent désormais d'un environnement cohérent, scalable et maintenable, capable de s'adapter aux besoins croissants de l'entreprise.
Ce mémoire présente les différentes étapes de conception et de mise en œuvre de cette solution, ainsi que
les résultats obtenus. Il met en lumière l'importance de l'automatisation, de la sécurité et de l'observabilité dans la gestion des infrastructures modernes, et ouvre la voie à de futures améliorations et innovations au sein de Oneex.
Ce projet s'inscrit dans une démarche continue d'amélioration et d'optimisation des processus
et expliquer la securité par design vs la securité par obscurité. Il est essentiel de continuer à investir dans la formation des équipes, l'évolution des outils et la mise en place de bonnes pratiques pour garantir la pérennité et la sécurité de l'infrastructure.
\subsection{Perspectives d'évolution}

L’approche \textbf{Infra\_v2} ouvre la voie à plusieurs évolutions futures permettant d’améliorer encore la performance, la fiabilité et la maintenabilité des systèmes :

\begin{itemize}
	\item \textbf{Renforcement de l’automatisation} : intégrer davantage de processus automatisés (tests d’intégration, vérifications de sécurité, audits de conformité) dans les pipelines CI/CD.

	\item \textbf{Observabilité avancée} : enrichir la télémétrie avec OpenTelemetry afin de collecter traces, métriques et logs de manière unifiée, facilitant le diagnostic en temps réel.

	\item \textbf{Scalabilité horizontale} : étendre la capacité de la plateforme Kubernetes en ajoutant dynamiquement des nœuds selon la charge.

	\item \textbf{Sécurité renforcée} : généraliser le chiffrement des communications internes, la rotation automatique des secrets et le principe de moindre privilège.

	\item \textbf{Standardisation des workflows} : promouvoir l’utilisation systématique de GitOps pour toutes les équipes afin de garantir une cohérence des pratiques de déploiement.

	\item \textbf{Optimisation des coûts} : introduire des mécanismes de scaling automatique et de surveillance des ressources afin de réduire les coûts d’infrastructure.
\end{itemize}

Ces perspectives s’inscrivent dans une démarche d’amélioration continue visant à industrialiser et fiabiliser la gestion des environnements techniques.

\subsection{Les points forts et faibles du point de vue technique et organisationnel}

\textbf{Points forts techniques :}
\begin{itemize}
	\item Infrastructure déclarative et versionnée, facilitant la reproductibilité et la traçabilité des changements.
	\item Automatisation complète du cycle de vie des environnements (provisionnement, configuration, déploiement).
	\item Haute disponibilité native grâce à Kubernetes et au découplage des composants.
	\item Facilité de rollback rapide en cas d’erreur.
	\item Intégration transparente de la gestion des secrets via Vault.
\end{itemize}

\textbf{Points faibles techniques :}
\begin{itemize}
	\item Courbe d’apprentissage élevée pour maîtriser l’ensemble des outils (Terraform, Ansible, Kubernetes, ArgoCD).
	\item Complexité accrue du système global nécessitant une veille technologique régulière.
	\item Dépendance à l’intégrité des outils d’orchestration (un dysfonctionnement de GitOps ou de l’API Kubernetes peut impacter la disponibilité).
\end{itemize}

\textbf{Points forts organisationnels :}
\begin{itemize}
	\item Processus standardisés réduisant les erreurs humaines.
	\item Visibilité complète des configurations via Git.
	\item Meilleure collaboration entre les équipes grâce à une approche déclarative et transparente.
	\item Accélération des cycles de déploiement.
\end{itemize}

\textbf{Points faibles organisationnels :}
\begin{itemize}
	\item Nécessité d’une conduite du changement importante pour faire adopter les nouveaux outils.
	\item Risque de silos de compétences si la montée en compétence n’est pas homogène au sein des équipes.
	\item Temps initial d’implémentation élevé pour mettre en place les pipelines et standardiser les pratiques.
\end{itemize}
