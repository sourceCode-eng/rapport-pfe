\section{Presentation des outils GitOps}
\subsection{Argo CD}

Argo CD est un outil open source de déploiement continu (CD) natif Kubernetes, conçu pour mettre en œuvre les pratiques GitOps. Il permet de synchroniser l’état désiré des applications, défini dans un dépôt Git, avec l’état effectif du cluster Kubernetes. En automatisant la gestion et le déploiement des manifestes, Argo CD apporte cohérence, traçabilité et résilience aux environnements cloud-native.

%point de vue metier
Argo CD répond à plusieurs enjeux stratégiques  : fiabiliser les déploiements, réduire le temps de mise en production, renforcer la traçabilité et limiter les erreurs humaines. Il offre un modèle déclaratif et auditable, conforme aux exigences de sécurité et de conformité des organisations modernes. En industrialisant le GitOps, Argo CD contribue à accélérer l’innovation tout en garantissant la stabilité des systèmes.

%point de vue logique et technique
, Argo CD s’appuie sur plusieurs composants clés  :
\begin{itemize}
	\item \textbf{Le dépôt Git}  : source unique de vérité contenant les manifestes Kubernetes (YAML) ou les définitions Kustomize/Helm.
	\item \textbf{Le contrôleur Argo CD}  : composant qui surveille les différences entre l’état souhaité (Git) et l’état réel du cluster.
	\item \textbf{L’API Server et l’interface Web}  : couche d’administration et de visualisation centralisée des applications et des synchronisations.
	\item \textbf{Les applications}  : objets Kubernetes représentant l’état désiré d’un ensemble de ressources.
	\item \textbf{Les stratégies de synchronisation}  : modes automatique ou manuel permettant de contrôler les mises à jour.
\end{itemize}

Argo CD offre un modèle de sécurité avancé, intégrant la gestion fine des permissions (RBAC), le support du SSO (OAuth2, OIDC), le chiffrement des secrets et des validations automatiques des changements.

\textbf{Exemples et cas d’usage} :
\begin{itemize}
	\item Déployer automatiquement une application Helm versionnée depuis un dépôt Git centralisé.
	\item Gérer des environnements multiples (dev, staging, production) avec des dossiers ou des branches distinctes.
	\item Appliquer des politiques de synchronisation automatique avec validation de signature Git.
	\item Visualiser les différences entre l’état courant et l’état cible et lancer un déploiement manuel.
	\item Auditer l’historique des déploiements et des changements appliqués au cluster.
\end{itemize}

\textbf{Avantages principaux} :
\begin{itemize}
	\item Mise en œuvre native du GitOps et centralisation de la configuration déclarative.
	\item Traçabilité et auditabilité complètes des changements.
	\item Intégration fluide avec Helm, Kustomize, Jsonnet et plain YAML.
	\item Réduction du risque d’erreurs grâce au contrôle automatique des dérives d’état.
	\item Interface Web ergonomique et API REST.
	\item Sécurité renforcée avec RBAC et chiffrement des secrets.
\end{itemize}

En synthèse, Argo CD est une solution stratégique pour l’automatisation et la fiabilisation des déploiements Kubernetes. Il contribue à instaurer des workflows GitOps robustes, cohérents et évolutifs, adaptés aux exigences opérationnelles des entreprises modernes.

\textbf{Références suggérées} :
\begin{itemize}
	\item Argo CD Documentation – \url{https://argo-cd.readthedocs.io/}
	\item Argo CD GitHub Repository – \url{https://github.com/argoproj/argo-cd}
	\item GitOps Principles – \url{https://www.gitops.tech/}
	\item CNCF Argo Project – \url{https://www.cncf.io/projects/argo/}
	\item Helm Documentation – \url{https://helm.sh/docs/}
\end{itemize}

\subsection{MetalLB}

MetalLB est un contrôleur open source qui permet d’apporter des capacités de Load Balancing de type L2/L3 à un cluster Kubernetes installé dans un environnement on-premise ou sur une infrastructure dépourvue de load balancer natif. En offrant une solution simple et efficace pour gérer les adresses IP externes, MetalLB comble une lacune importante des clusters bare-metal en production.

%point de vue metier
MetalLB répond à plusieurs enjeux  : rendre les services Kubernetes accessibles de manière fiable, offrir une expérience équivalente à celle des clouds publics, et garantir la continuité de service en cas de défaillance d’un nœud. Il permet aux organisations d’exploiter Kubernetes dans leurs datacenters ou clouds privés tout en bénéficiant des standards d’exposition réseau attendus par les utilisateurs et les clients.

%point de vue logique et technique
, MetalLB fonctionne selon deux modes principaux :
\begin{itemize}
	\item \textbf{Le mode Layer 2}  : chaque nœud participant annonce l’IP publique via ARP (IPv4) ou NDP (IPv6). Ce mode est simple à déployer et ne nécessite pas de routeur compatible BGP.
	\item \textbf{Le mode BGP}  : MetalLB établit une session BGP avec les routeurs de l’infrastructure pour annoncer dynamiquement les plages IP attribuées aux services.
\end{itemize}

MetalLB s’intègre nativement au modèle Kubernetes via l’objet \texttt{Service} de type LoadBalancer, permettant aux workloads d’exposer des ports vers l’extérieur sans nécessiter de composants supplémentaires côté application.

\textbf{Exemples et cas d’usage} :
\begin{itemize}
	\item Attribuer automatiquement une IP publique à un service NGINX déployé sur Kubernetes on-premise.
	\item Utiliser le mode BGP pour une intégration avancée avec le routeur du datacenter.
	\item Mettre en place une plage IP dédiée aux services LoadBalancer et contrôler leur allocation via un ConfigMap.
	\item Fournir des adresses IP statiques pour des applications critiques nécessitant des endpoints fixes.
	\item Simplifier l’exposition des APIs internes et des dashboards à des clients internes ou externes.
\end{itemize}

\textbf{Avantages principaux} :
\begin{itemize}
	\item Offre des capacités de Load Balancing natives à Kubernetes sans infrastructure cloud.
	\item Déploiement simple et flexible (mode L2 ou BGP).
	\item Compatibilité totale avec l’API Kubernetes standard (Service type LoadBalancer).
	\item Haute disponibilité et résilience grâce à la gestion automatique des annonces réseau.
	\item Solution open source mature et largement adoptée.
\end{itemize}

En synthèse, MetalLB est une brique essentielle pour rendre Kubernetes opérationnel en production dans des environnements bare-metal et hybrides. Il permet aux organisations de standardiser l’exposition des services tout en préservant leur autonomie vis-à-vis des fournisseurs cloud.

\textbf{Références suggérées} :
\begin{itemize}
	\item MetalLB Documentation – \url{https://metallb.universe.tf/}
	\item MetalLB GitHub Repository – \url{https://github.com/metallb/metallb}
	\item Kubernetes Services Documentation – \url{https://kubernetes.io/docs/concepts/services-networking/service/}
	\item BGP Overview – \url{https://www.networklessons.com/bgp/bgp-basics/}
	\item Kubernetes Bare Metal – \url{https://kubernetes.io/docs/setup/production-environment/turnkey/}
\end{itemize}

\subsection{NGINX}

NGINX est un serveur web open source reconnu pour ses performances élevées, sa faible consommation de ressources et sa polyvalence. Initialement conçu comme un serveur HTTP haute performance et un reverse proxy, NGINX est devenu une plateforme complète capable d’assurer des rôles variés  : load balancer, cache HTTP, proxy TLS/SSL, terminator TLS, et serveur d’applications via FastCGI, SCGI ou uWSGI.

%point de vue metier
NGINX répond à des enjeux stratégiques  : améliorer la rapidité et la fiabilité des applications web, optimiser les coûts d’infrastructure et assurer une expérience utilisateur optimale. Grâce à sa capacité à servir des milliers de connexions simultanées avec une faible empreinte mémoire, il est adopté aussi bien par les start-ups que par les grandes entreprises. Il joue également un rôle clé dans la sécurisation des services exposés sur Internet.

%point de vue logique et technique
, NGINX s’appuie sur une architecture événementielle asynchrone qui lui permet de traiter un grand nombre de requêtes concurrentes sans blocage. Ses fonctionnalités couvrent notamment  :
\begin{itemize}
	\item \textbf{Reverse proxy}  : réception des requêtes HTTP(S) et distribution vers les serveurs applicatifs backend.
	\item \textbf{Load balancing}  : répartition du trafic selon des stratégies (round-robin, least connections, IP hash).
	\item \textbf{Caching}  : mise en cache des contenus statiques et dynamiques pour réduire la charge des serveurs backend.
	\item \textbf{TLS termination}  : déchiffrement des connexions HTTPS.
	\item \textbf{Serveur statique}  : hébergement direct de contenus (HTML, CSS, JS, images).
	\item \textbf{Rewrite et redirection}  : réécriture des URLs et redirections conditionnelles.
\end{itemize}

NGINX peut être utilisé seul ou intégré dans des architectures plus complexes, notamment en combinaison avec Kubernetes (Ingress Controller) et des plateformes cloud.

\textbf{Exemples et cas d’usage} :
\begin{itemize}
	\item Servir un site web statique et proxyfier les appels d’API vers un backend Node.js.
	\item Répartir les requêtes HTTP entre plusieurs instances d’application avec un algorithme round-robin.
	\item Terminer les connexions TLS et rediriger automatiquement le trafic HTTP vers HTTPS.
	\item Mettre en cache les réponses d’un serveur applicatif pour améliorer la rapidité des pages.
	\item Utiliser NGINX Ingress Controller dans Kubernetes pour exposer des services internes via un point d’accès unique.
\end{itemize}

\textbf{Avantages principaux} :
\begin{itemize}
	\item Performance élevée et faible consommation mémoire.
	\item Architecture asynchrone adaptée aux charges importantes.
	\item Polyvalence (reverse proxy, load balancer, cache, serveur statique).
	\item Large compatibilité avec les standards HTTP et TLS.
	\item Intégration fluide avec Kubernetes et l’écosystème cloud-native.
	\item Solution open source mature, soutenue par une large communauté.
\end{itemize}

En synthèse, NGINX est une brique technologique incontournable des infrastructures web modernes. Il offre une combinaison unique de performance, de fiabilité et de flexibilité, adaptée aux besoins des applications critiques et distribuées.

\textbf{Références suggérées} :
\begin{itemize}
	\item NGINX Documentation – \url{https://nginx.org/en/docs/}
	\item NGINX GitHub Repository – \url{https://github.com/nginx/nginx}
	\item NGINX Ingress Controller – \url{https://kubernetes.github.io/ingress-nginx/}
	\item Garrett, C. (2017). \textit{NGINX Cookbook}. O’Reilly Media.
	\item NGINX Blog – \url{https://www.nginx.com/blog/}
\end{itemize}

\section{Mise en œuvre du modèle GitOps}

Le modèle GitOps vise à centraliser la définition de l’infrastructure et des applications dans des dépôts Git versionnés, en s’appuyant sur un opérateur qui applique automatiquement l’état souhaité dans le cluster Kubernetes.
Dans ce projet, l’outil \textbf{Argo CD} a été retenu pour assurer ce rôle.
La démarche GitOps permet d’améliorer la traçabilité, la cohérence et l’automatisation des déploiements.

\subsection{Préparation des manifestes des outils internes}

Avant l’installation d’Argo CD, les manifestes Kubernetes décrivant les composants internes nécessaires au bon fonctionnement de la plateforme ont été préparés.
Ces manifestes incluent :
\begin{itemize}
	\item Les configurations des namespaces réservés (par exemple \texttt{argocd}, \texttt{monitoring}, \texttt{tools}).
	\item Les déploiements de services annexes tels que les opérateurs de sauvegarde et les contrôleurs réseau.
	\item Les configurations des ressources communes (ConfigMaps, Secrets, RBAC).
\end{itemize}

L’ensemble de ces manifestes est versionné dans un dépôt Git dédié à l’infrastructure, garantissant une source unique de vérité et la possibilité de reconstruire intégralement l’environnement.

\subsection{Installation d’Argo CD}

L’installation d’Argo CD a été réalisée via l’application des manifestes officiels fournis par le projet.
Le processus s’effectue en deux étapes principales :
\begin{itemize}
	\item Création du namespace dédié (\texttt{argocd}).
	\item Application du manifest d’installation complet :
	      \begin{verbatim}
kubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml
\end{verbatim}
\end{itemize}

Après l’installation, les pods principaux (API server, repo server, application controller et dex) sont déployés automatiquement.
L’interface web d’Argo CD permet de superviser les applications GitOps et leur état de synchronisation.

\subsection{Configuration de l’authentification}

La sécurisation de l’accès à Argo CD est essentielle.
Les mesures suivantes ont été mises en place :
\begin{itemize}
	\item Activation de l’authentification via Dex avec un connecteur LDAP, permettant une intégration avec l’annuaire interne.
	\item Création de rôles et de policies RBAC pour définir des droits différenciés selon les équipes (lecture seule, modification, administration).
	\item Rotation automatique des tokens d’accès.
	\item Activation de TLS pour sécuriser les communications avec l’interface web.
\end{itemize}

Ces mécanismes garantissent que seuls les utilisateurs autorisés peuvent interagir avec les ressources et déclencher des déploiements.

\subsection{Configuration des synchronisations}

La synchronisation automatique entre l’état déclaré dans Git et l’état réel du cluster est un principe fondamental de GitOps.
Argo CD a été configuré avec les paramètres suivants :
\begin{itemize}
	\item Mode de synchronisation automatique (\texttt{auto-sync}) activé sur les applications critiques.
	\item Validation stricte des manifests avant application.
	\item Prise en charge des stratégies de \textit{pruning} pour supprimer les ressources obsolètes.
	\item Notification par webhook et alerting en cas d’écart détecté entre l’état souhaité et l’état courant.
\end{itemize}

Cette configuration permet de garantir que le cluster converge toujours vers l’état décrit dans les dépôts Git et de détecter les modifications manuelles non autorisées.

\subsection{Préparation des manifestes des applications développées par Oneex pour des environnements différents}

Les applications développées par Oneex ont été déployées sur plusieurs environnements (développement, recette, production).
Pour assurer la cohérence et l’adaptabilité, les manifestes Kubernetes ont été préparés selon les principes suivants :
\begin{itemize}
	\item Utilisation de \texttt{kustomize} pour générer des variantes par environnement (par exemple configuration des replicas, des ressources et des variables d’environnement).
	\item Définition de ConfigMaps et de Secrets séparés selon les contextes.
	\item Structuration des dépôts Git avec des arborescences claires par application et par environnement.
	\item Mise en place de règles de validation continue (linting et contrôle de schéma) avant validation des commits.
\end{itemize}

Cette approche permet de disposer d’un processus de déploiement uniforme, de simplifier la maintenance et de garantir que chaque environnement est conforme aux spécifications attendues.
