\section{Introduction}

L’observabilité constitue un pilier essentiel dans la gestion moderne des systèmes distribués. Elle regroupe l’ensemble des pratiques, outils et processus permettant de comprendre le comportement d’une infrastructure, de détecter les anomalies et de garantir la conformité aux exigences de sécurité et de qualité de service.

Dans le contexte des architectures conteneurisées et des microservices, la complexité opérationnelle s’est fortement accrue. Chaque requête peut transiter par de nombreux composants, rendant le diagnostic des incidents particulièrement difficile sans outils adaptés.

Par ailleurs, les exigences réglementaires et les bonnes pratiques imposent de disposer d’audits précis des accès, des changements et des événements critiques. L’observabilité et l’audit ne se limitent donc pas à la simple surveillance technique, mais participent également à la gouvernance et à la gestion des risques.

Enfin, il est important de souligner que surveiller uniquement des métriques brutes telles que l’utilisation CPU ou mémoire (« CPU à 80 \% », par exemple) n’est pas suffisant. Ces indicateurs doivent être replacés dans leur contexte et enrichis par des analyses plus poussées (traçage distribué, corrélation d’événements, détection d’anomalies, etc.), comme nous le verrons dans les chapitres suivants.

\subsection{Contexte et enjeux de l'observabilité et de l'audit}

La mise en place d’un dispositif d’observabilité répond à plusieurs enjeux majeurs :

\begin{itemize}
	\item \textbf{Diagnostic rapide des incidents} : être capable de reconstituer le scénario précis ayant conduit à une panne ou à un comportement inattendu.
	\item \textbf{Optimisation des performances} : mesurer et analyser les temps de réponse, l’utilisation des ressources et la saturation éventuelle des composants.
	\item \textbf{Sécurité et traçabilité} : enregistrer les accès, les tentatives d’intrusion et les changements de configuration, afin de disposer de preuves en cas d’incident de sécurité.
	\item \textbf{Conformité réglementaire} : répondre aux obligations légales ou contractuelles en matière de conservation des journaux et de traçabilité des actions (par exemple, RGPD, ISO 27001).
	\item \textbf{Amélioration continue} : exploiter les données collectées pour identifier les points faibles et guider les évolutions de l’architecture.
\end{itemize}

Dans le cadre de ce projet, l’objectif est de fournir une visibilité unifiée sur l’état de l’infrastructure Kubernetes, des services applicatifs et des flux réseau, en s’appuyant sur des outils open source et des processus automatisés.

\section{État de l'art et tendances actuelles}

L’état de l’art de l’observabilité se structure autour de trois piliers principaux, souvent désignés sous l’acronyme \textbf{MELT} (Metrics, Events, Logs, Traces) :

\begin{enumerate}
	\item \textbf{Les métriques} : valeurs numériques collectées à intervalles réguliers (CPU, mémoire, latence). Des solutions comme Prometheus ou InfluxDB permettent de stocker et d’interroger ces mesures.
	\item \textbf{Les événements et alertes} : notifications déclenchées par un seuil ou un changement d’état. Ces événements sont souvent gérés par Alertmanager ou des systèmes de gestion d’incidents (PagerDuty, Opsgenie).
	\item \textbf{Les logs} : traces textuelles produites par les applications et les composants système. Les solutions modernes (Elastic Stack, Loki) facilitent la collecte et la recherche en temps réel.
	\item \textbf{Les traces distribuées} : enregistrements du parcours d’une requête à travers les microservices. Des outils comme Jaeger et OpenTelemetry sont devenus des standards de facto.
\end{enumerate}

Les tendances actuelles mettent en avant plusieurs évolutions :

\begin{itemize}
	\item \textbf{L’adoption massive de l’open source} : la plupart des organisations privilégient des solutions libres et communautaires pour éviter l’enfermement propriétaire.
	\item \textbf{Le modèle as-a-Service} : de nombreux acteurs (Datadog, New Relic, Grafana Cloud) proposent des plateformes hébergées intégrant l’ensemble des fonctionnalités d’observabilité.
	\item \textbf{La convergence des données} : les métriques, logs et traces ne sont plus traités isolément mais regroupés dans des plateformes unifiées facilitant les corrélations.
	\item \textbf{L’intégration avec GitOps et l’automatisation} : les configurations de monitoring et d’alerting sont versionnées et déployées de la même manière que les ressources Kubernetes.
	\item \textbf{La montée en puissance d’OpenTelemetry} : ce projet CNCF s’impose comme le standard unique de collecte de la télémétrie dans les environnements cloud-native.
\end{itemize}

Ces évolutions permettent de construire des systèmes plus résilients, plus sécurisés et plus faciles à maintenir, tout en apportant une meilleure compréhension globale des environnements complexes.

\subsection{Grafana}

Grafana est une solution open source de visualisation et d’exploration de données, largement utilisée pour la supervision des infrastructures, le monitoring applicatif et l’analyse d’indicateurs métiers. Elle permet de créer des tableaux de bord interactifs et personnalisables qui agrègent des données provenant de multiples sources (Prometheus, InfluxDB, Elasticsearch, Loki, MySQL, etc.). Grâce à son approche modulaire et à sa richesse fonctionnelle, Grafana s’est imposé comme un standard de facto dans l’écosystème cloud-native et DevOps.

%point de vue metier
Grafana répond à plusieurs enjeux stratégiques  : renforcer la visibilité sur les systèmes critiques, réduire le temps de résolution des incidents, et améliorer la qualité des services. En centralisant la visualisation et l’analyse des métriques, logs et traces, Grafana facilite la prise de décision et contribue à l’amélioration continue des processus opérationnels. Son interface conviviale et ses capacités de partage simplifient la collaboration entre équipes techniques et parties prenantes.

%point de vue logique et technique
, Grafana repose sur plusieurs composants essentiels  :
\begin{itemize}
	\item \textbf{Les datasources}  : connecteurs vers des bases de données et des systèmes de monitoring (Prometheus, Graphite, ElasticSearch, CloudWatch, etc.).
	\item \textbf{Les dashboards}  : ensembles de panels configurables qui visualisent les données sous forme de graphiques, jauges, tableaux et alertes.
	\item \textbf{Les panels}  : éléments de visualisation individuels, paramétrés avec des requêtes, des transformations et des styles personnalisés.
	\item \textbf{Les alertes}  : règles qui surveillent les seuils définis et déclenchent des notifications en cas d’anomalie.
	\item \textbf{Les organisations et utilisateurs}  : système de gestion des accès, des permissions et des partages.
\end{itemize}

Grafana peut être déployé en standalone ou intégré dans des stacks d’observabilité complètes (exemple  : Prometheus + Loki + Grafana). Son API REST et son support des plugins en font un outil particulièrement extensible et adaptable à tous les cas d’usage.

\textbf{Exemples et cas d’usage} :
\begin{itemize}
	\item Visualiser en temps réel les métriques d’un cluster Kubernetes (CPU, mémoire, pods, etc.) en s’appuyant sur Prometheus.
	\item Corréler les logs applicatifs via Loki avec les indicateurs de performance pour diagnostiquer plus rapidement un incident.
	\item Configurer des alertes pour notifier les équipes DevOps en cas de dépassement d’un seuil critique (ex. latence élevée).
	\item Créer des tableaux de bord métiers synthétiques avec des indicateurs clés (KPI) accessibles aux décideurs.
	\item Intégrer Grafana avec Slack ou PagerDuty pour centraliser les alertes et les escalades.
\end{itemize}

\textbf{Avantages principaux} :
\begin{itemize}
	\item Plateforme unifiée de visualisation multi-sources et multi-formats.
	\item Interface ergonomique et hautement personnalisable.
	\item Large écosystème de plugins, dashboards communautaires et connecteurs.
	\item Support des alertes natives et intégration avec les systèmes de notification.
	\item Extensibilité via API REST, provisioning as code et gestion des permissions fine.
	\item Solution open source mature, supportée par une large communauté.
\end{itemize}

En synthèse, Grafana est une brique centrale des stratégies d’observabilité modernes. Il permet aux organisations de transformer leurs données en connaissances actionnables, d’améliorer la performance opérationnelle et de renforcer la confiance dans les systèmes distribués.

\textbf{Références suggérées} :
\begin{itemize}
	\item Grafana Documentation – \url{https://grafana.com/docs/}
	\item Grafana GitHub Repository – \url{https://github.com/grafana/grafana}
	\item Prometheus Documentation – \url{https://prometheus.io/docs/}
	\item Loki Documentation – \url{https://grafana.com/docs/loki/latest/}
	\item Grafana Labs Blog – \url{https://grafana.com/blog/}
\end{itemize}

\subsection{Prometheus}

Prometheus est une solution open source de monitoring et d’alerte initialement développée par SoundCloud, puis incubée par la Cloud Native Computing Foundation (CNCF). Il est devenu l’un des piliers des architectures cloud-native grâce à sa capacité à collecter, stocker et interroger des métriques temporelles de manière performante. Prometheus est particulièrement reconnu pour son modèle de données multidimensionnel, son langage de requête puissant (PromQL) et sa facilité d’intégration avec Kubernetes.

%point de vue metier
Prometheus répond à plusieurs enjeux essentiels  : renforcer la visibilité sur les systèmes critiques, anticiper les incidents par une surveillance proactive et réduire le temps moyen de résolution des problèmes (MTTR). Il contribue à l’amélioration continue des performances applicatives et à la qualité de service délivrée aux utilisateurs. Grâce à sa modularité, Prometheus s’adapte à des environnements variés (infrastructures cloud, conteneurs, clusters Kubernetes, applications legacy).

%point de vue logique et technique
, Prometheus repose sur plusieurs composants clés  :
\begin{itemize}
	\item \textbf{Le serveur Prometheus}  : responsable de la collecte des métriques via le protocole HTTP/HTTPS (pull model) et du stockage local des séries temporelles.
	\item \textbf{Les exporters}  : processus ou agents qui exposent des métriques au format Prometheus (ex.: Node Exporter, Blackbox Exporter, MySQL Exporter).
	\item \textbf{Le langage PromQL}  : langage de requête permettant d’agréger, filtrer et analyser les métriques.
	\item \textbf{Les règles d’alerte}  : expressions PromQL évaluées en continu pour générer des alertes.
	\item \textbf{Alertmanager}  : composant dédié à la gestion et au routage des alertes vers les canaux de notification (email, Slack, PagerDuty).
\end{itemize}

Prometheus est particulièrement bien intégré dans l’écosystème Kubernetes grâce à la découverte de services automatique, facilitant ainsi la supervision des clusters et des workloads dynamiques.

\textbf{Exemples et cas d’usage} :
\begin{itemize}
	\item Superviser l’utilisation CPU et mémoire des nœuds Kubernetes via Node Exporter.
	\item Mesurer la latence et le taux d’erreurs des endpoints HTTP exposés par des microservices.
	\item Définir une alerte déclenchée lorsque la disponibilité d’un service passe sous un seuil critique.
	\item Stocker des métriques de performance applicative pour des analyses historiques.
	\item Visualiser les métriques dans Grafana grâce au connecteur natif Prometheus.
\end{itemize}

\textbf{Avantages principaux} :
\begin{itemize}
	\item Modèle de collecte pull simplifiant l’intégration avec les workloads dynamiques.
	\item Stockage en séries temporelles optimisé pour la performance et la rétention longue durée.
	\item Langage PromQL expressif et puissant pour l’analyse des données.
	\item Intégration native avec Kubernetes et les architectures cloud-native.
	\item Écosystème riche d’exporters et de dashboards communautaires.
	\item Solution open source mature, soutenue par la CNCF et une large communauté.
\end{itemize}

En synthèse, Prometheus est un outil incontournable des stratégies de monitoring et d’observabilité modernes. Il apporte robustesse, flexibilité et transparence à la supervision des infrastructures complexes et des applications distribuées.

\textbf{Références suggérées} :
\begin{itemize}
	\item Prometheus Documentation – \url{https://prometheus.io/docs/}
	\item Prometheus GitHub Repository – \url{https://github.com/prometheus/prometheus}
	\item CNCF Prometheus Project – \url{https://www.cncf.io/projects/prometheus/}
	\item Grafana Documentation – \url{https://grafana.com/docs/grafana/latest/datasources/prometheus/}
	\item Monitoring with Prometheus – James Turnbull. O’Reilly Media.
\end{itemize}

\subsection{Loki}

Loki est une solution open source développée par Grafana Labs pour la centralisation et l’analyse des logs. Conçu pour s’intégrer étroitement avec Prometheus, Grafana et l’écosystème cloud-native, Loki adopte une approche innovante  : il indexe uniquement les labels (métadonnées) et non le contenu complet des logs. Cette caractéristique en fait une solution plus légère, plus scalable et plus économique que les systèmes traditionnels d’indexation complète (par exemple Elasticsearch).

%point de vue metier
Loki répond à plusieurs enjeux stratégiques  : renforcer la visibilité sur les applications et les infrastructures, accélérer les diagnostics d’incidents et réduire le coût du stockage et du traitement des logs. Il permet aux équipes SRE, DevOps et de support de disposer d’un outil cohérent avec leur stack de monitoring et d’observabilité, facilitant la corrélation entre métriques, logs et alertes.

%point de vue logique et technique
, Loki repose sur plusieurs concepts clés  :
\begin{itemize}
	\item \textbf{Les labels}  : clés et valeurs attachées aux streams de logs (par exemple `app="nginx"`), utilisés comme index.
	\item \textbf{Les chunks}  : segments de données compressées regroupant les logs non indexés.
	\item \textbf{Promtail}  : agent qui collecte les logs sur les hôtes et les envoie à Loki.
	\item \textbf{Le langage LogQL}  : langage de requête inspiré de PromQL, permettant d’interroger et d’agréger les logs.
	\item \textbf{L’intégration Grafana}  : visualisation et exploration des logs dans des dashboards unifiés.
\end{itemize}

Grâce à sa compatibilité Kubernetes et à sa scalabilité horizontale, Loki est particulièrement adapté aux environnements cloud-native et microservices.

\textbf{Exemples et cas d’usage} :
\begin{itemize}
	\item Collecter les logs des conteneurs Kubernetes via Promtail et les regrouper par namespace, pod et container.
	\item Corréler des pics de latence observés dans Prometheus avec les logs applicatifs de la même période.
	\item Configurer une alerte Grafana qui affiche les logs d’erreurs critiques lors d’un incident.
	\item Archiver les logs applicatifs de manière compressée et économique sur le long terme.
	\item Rechercher rapidement les logs d’un service particulier via LogQL.
\end{itemize}

\textbf{Avantages principaux} :
\begin{itemize}
	\item Scalabilité horizontale et stockage économique grâce à l’indexation minimale.
	\item Intégration native avec Grafana et Prometheus.
	\item Requêtes puissantes et flexibles avec LogQL.
	\item Support complet de Kubernetes et des environnements multi-cloud.
	\item Solution open source mature et soutenue par une large communauté.
\end{itemize}

En synthèse, Loki est un composant central de la stack d’observabilité cloud-native. Il permet aux organisations de simplifier et de rationaliser la gestion des logs, tout en réduisant les coûts et en améliorant la capacité de diagnostic et de supervision.

\textbf{Références suggérées} :
\begin{itemize}
	\item Loki Documentation – \url{https://grafana.com/docs/loki/latest/}
	\item Loki GitHub Repository – \url{https://github.com/grafana/loki}
	\item Grafana Documentation – \url{https://grafana.com/docs/}
	\item Promtail Documentation – \url{https://grafana.com/docs/loki/latest/clients/promtail/}
	\item CNCF Loki Project – \url{https://www.cncf.io/projects/loki/}
\end{itemize}

\subsection{Tempo}

Tempo est une solution open source de traçage distribué développée par Grafana Labs. Elle permet de collecter, stocker et interroger des traces issues d’applications distribuées, sans nécessiter d’indexation complexe. Conçu pour compléter Prometheus et Loki, Tempo s’intègre naturellement dans la stack d’observabilité cloud-native. Grâce à son architecture optimisée, il offre un stockage massif et économique des traces, tout en simplifiant la corrélation avec les métriques et les logs.

%point de vue metier
Tempo répond à plusieurs enjeux stratégiques  : comprendre la performance des applications microservices, diagnostiquer les latences et les erreurs en production, et améliorer l’expérience utilisateur. En facilitant l’analyse des parcours complets des requêtes, Tempo contribue à réduire le temps moyen de résolution des incidents (MTTR) et à optimiser la qualité de service.

%point de vue logique et technique
, Tempo s’appuie sur plusieurs concepts essentiels  :
\begin{itemize}
	\item \textbf{Les traces}  : enregistrements d’un ensemble de spans représentant les étapes d’une requête distribuée.
	\item \textbf{Les spans}  : unités atomiques contenant les métadonnées sur chaque étape (durée, étiquettes, événements).
	\item \textbf{L’ingester}  : composant qui reçoit et stocke les traces dans des blocs compressés.
	\item \textbf{L’indexation minimale}  : Tempo utilise un modèle «  No Index  », reposant uniquement sur l’identifiant de trace, ce qui simplifie le stockage et réduit les coûts.
	\item \textbf{L’intégration avec Grafana}  : Tempo permet de visualiser et de rechercher les traces via l’interface Grafana, en corrélation avec les métriques Prometheus et les logs Loki.
\end{itemize}

Tempo est compatible avec les formats de traçage standardisés comme OpenTelemetry, Jaeger et Zipkin, facilitant l’intégration avec un grand nombre de frameworks et de langages.

\textbf{Exemples et cas d’usage} :
\begin{itemize}
	\item Collecter les traces d’une application microservices instrumentée avec OpenTelemetry.
	\item Corréler un pic de latence observé dans Prometheus avec les traces détaillant les appels entre services.
	\item Rechercher des traces via leur identifiant unique depuis un log collecté par Loki.
	\item Visualiser les dépendances entre services et la durée de chaque étape d’une requête.
	\item Conserver l’historique des traces pour analyse et optimisation des performances applicatives.
\end{itemize}

\textbf{Avantages principaux} :
\begin{itemize}
	\item Scalabilité horizontale et stockage économique sans indexation complexe.
	\item Compatibilité native avec OpenTelemetry, Jaeger et Zipkin.
	\item Corrélation simple avec les métriques et logs via Grafana.
	\item Facilité de déploiement dans des environnements Kubernetes et cloud.
	\item Solution open source soutenue par la CNCF et Grafana Labs.
\end{itemize}

En synthèse, Tempo est un pilier des architectures d’observabilité modernes. Il apporte visibilité, compréhension et capacité de diagnostic sur les systèmes distribués, en complément parfait de Prometheus et Loki.

\textbf{Références suggérées} :
\begin{itemize}
	\item Tempo Documentation – \url{https://grafana.com/docs/tempo/latest/}
	\item Tempo GitHub Repository – \url{https://github.com/grafana/tempo}
	\item OpenTelemetry Documentation – \url{https://opentelemetry.io/docs/}
	\item Jaeger Documentation – \url{https://www.jaegertracing.io/docs/}
	\item Grafana Labs Blog – \url{https://grafana.com/blog/}
\end{itemize}

% \subsection{OpenTelemetry}

% OpenTelemetry est une suite open source de spécifications, d’outils et de SDK destinée à la collecte, au traitement et à l’exportation des signaux d’observabilité  : métriques, logs et traces. Né de la fusion des projets OpenTracing et OpenCensus, OpenTelemetry est aujourd’hui un projet de la Cloud Native Computing Foundation (CNCF) et constitue le standard de facto pour instrumenter les applications modernes, qu’elles soient monolithiques ou microservices.

% %point de vue metier
% OpenTelemetry répond à des enjeux stratégiques majeurs  : renforcer la visibilité sur les systèmes distribués, anticiper les problèmes de performance, améliorer l’expérience utilisateur et faciliter la transformation digitale. En proposant un cadre unifié et standardisé, OpenTelemetry contribue à réduire la complexité opérationnelle et à accélérer la mise en place de stratégies d’observabilité efficaces.

% %point de vue logique et technique
% , OpenTelemetry repose sur plusieurs composants essentiels  :
% \begin{itemize}
% 	\item \textbf{Les SDK}  : bibliothèques spécifiques aux langages (Java, Go, Python, etc.) qui instrumentent automatiquement ou manuellement les applications.
% 	\item \textbf{Le Collector}  : service qui reçoit, traite et exporte les signaux vers des backends comme Prometheus, Jaeger, Tempo, Zipkin ou Grafana.
% 	\item \textbf{Les exporters}  : composants qui envoient les données collectées vers des systèmes tiers.
% 	\item \textbf{Les ressources}  : ensembles de métadonnées qui décrivent les attributs des services (nom, version, environnement).
% 	\item \textbf{Les protocoles}  : principalement OTLP (OpenTelemetry Protocol), conçu pour un transport efficace et interopérable des signaux.
% \end{itemize}

% OpenTelemetry est conçu comme un projet modulaire et extensible, permettant aux équipes d’adopter progressivement la collecte des traces, des métriques et des logs, selon leurs priorités.

% \textbf{Exemples et cas d’usage} :
% \begin{itemize}
% 	\item Instrumenter automatiquement une API REST en Java pour collecter les latences et les erreurs.
% 	\item Exporter les métriques applicatives vers Prometheus et les traces vers Tempo via le Collector.
% 	\item Corréler les logs et les traces grâce à des identifiants de corrélation injectés automatiquement.
% 	\item Visualiser le graphe de dépendances entre microservices dans Jaeger ou Grafana.
% 	\item Monitorer en temps réel les indicateurs de performance d’un cluster Kubernetes.
% \end{itemize}

% \textbf{Avantages principaux} :
% \begin{itemize}
% 	\item Standardisation des signaux d’observabilité (métriques, traces, logs).
% 	\item Large compatibilité multi-langages et multi-plateformes.
% 	\item Collecte et exportation flexibles via le Collector.
% 	\item Intégration fluide avec les principaux backends d’observabilité.
% 	\item Support actif par une large communauté et les principaux éditeurs cloud.
% 	\item Réduction de la complexité opérationnelle et meilleure visibilité end-to-end.
% \end{itemize}

% En synthèse, OpenTelemetry est une brique fondamentale de l’observabilité moderne. Il offre un cadre unifié, extensible et standardisé, permettant aux organisations de mieux comprendre et améliorer le comportement de leurs applications distribuées.

% \textbf{Références suggérées} :
% \begin{itemize}
% 	\item OpenTelemetry Documentation – \url{https://opentelemetry.io/docs/}
% 	\item OpenTelemetry GitHub – \url{https://github.com/open-telemetry/opentelemetry-specification}
% 	\item CNCF OpenTelemetry Project – \url{https://www.cncf.io/projects/opentelemetry/}
% 	\item Jaeger Documentation – \url{https://www.jaegertracing.io/docs/}
% 	\item Grafana Tempo Documentation – \url{https://grafana.com/docs/tempo/latest/}
% \end{itemize}

\section{Mise en place du monitoring continu}

La mise en place du monitoring continu est indispensable pour assurer la supervision proactive de l’infrastructure et des applications.
Le projet s’appuie principalement sur la solution Prometheus, qui collecte les métriques exposées par les composants Kubernetes et les services applicatifs via des endpoints HTTP (\texttt{/metrics}).

Les étapes principales comprennent :
\begin{itemize}
	\item Le déploiement de l’opérateur Prometheus dans le cluster Kubernetes.
	\item La définition des \texttt{ServiceMonitor} et \texttt{PodMonitor} permettant de déclarer les cibles à surveiller.
	\item La configuration des règles d’alerting basées sur les métriques collectées.
	\item L’intégration avec Grafana pour la visualisation en temps réel des tableaux de bord.
\end{itemize}

Grâce à cette approche, l’état des systèmes est suivi en continu et les anomalies peuvent être détectées de manière précoce.

\section{Gestion des alertes et des incidents}

La gestion des alertes repose sur l’utilisation de Prometheus Alertmanager.
Ce composant reçoit les alertes générées par Prometheus selon les règles prédéfinies (par exemple seuils de charge CPU, absence de pods, erreurs applicatives).

Les principaux éléments mis en place sont :
\begin{itemize}
	\item La configuration des routes d’alerte permettant d’acheminer les notifications vers les destinataires appropriés (e-mails, canaux Slack, systèmes d’escalade).
	\item La définition des silences pour désactiver temporairement des alertes lors de maintenances planifiées.
	\item L’organisation des alertes par sévérité et par environnement (développement, recette, production).
	\item La documentation des procédures de réponse aux incidents.
\end{itemize}

Ce dispositif contribue à réduire le temps moyen de résolution des incidents et à limiter leur impact sur les utilisateurs.

\section{Gestion des logs}

La collecte centralisée des logs est un pilier de l’observabilité.
Dans ce projet, la stack EFK (Elasticsearch, Fluentd, Kibana) ou Loki a été utilisée afin d’agréger les journaux produits par :
\begin{itemize}
	\item Les pods Kubernetes.
	\item Les composants système des nœuds.
	\item Les applications déployées.
\end{itemize}

Les principales fonctionnalités implémentées sont :
\begin{itemize}
	\item La normalisation et l’enrichissement des logs avec des métadonnées Kubernetes (namespace, nom du pod, labels).
	\item L’indexation et la conservation des journaux selon des politiques de rétention définies.
	\item La recherche en temps réel et la création de tableaux de bord personnalisés dans Kibana ou Grafana.
	\item La détection automatique d’événements critiques et la génération de notifications.
\end{itemize}

Cette centralisation des logs permet de gagner en efficacité lors des diagnostics et de garantir la traçabilité complète des événements.

\section{Gestion des traces distribuées}

Les traces distribuées apportent une vision fine du parcours des requêtes à travers les différents microservices.
Le projet s’appuie sur la suite OpenTelemetry pour instrumenter les applications et collecter les traces.

Les éléments mis en œuvre sont :
\begin{itemize}
	\item L’instrumentation automatique et manuelle du code pour générer des spans et propager le contexte de trace.
	\item Le déploiement du collector OpenTelemetry dans Kubernetes.
	\item L’export des traces vers un backend comme Jaeger ou Grafana Tempo.
	\item La visualisation des dépendances et des performances des requêtes via des interfaces web dédiées.
\end{itemize}

Les traces permettent notamment de :
\begin{itemize}
	\item Identifier les goulets d’étranglement et les sources de latence.
	\item Suivre l’impact des erreurs sur l’ensemble du parcours utilisateur.
	\item Corréler les traces avec les logs et les métriques.
\end{itemize}

\section{Automatisation des audits et de la conformité}

L’automatisation des audits et de la conformité vise à garantir le respect des exigences réglementaires et des politiques internes.

Pour atteindre cet objectif, plusieurs mesures ont été adoptées :
\begin{itemize}
	\item L’activation de l’audit logging Kubernetes pour enregistrer toutes les requêtes API et changements d’état.
	\item La centralisation des journaux d’audit dans Elasticsearch pour une conservation longue durée et une recherche efficace.
	\item La mise en place de règles de contrôle (OPA/Gatekeeper) validant les configurations déployées (politiques de sécurité, labels obligatoires, restrictions de privilèges).
	\item La génération automatique de rapports de conformité sur les accès et les déploiements.
\end{itemize}

Ces mécanismes facilitent les contrôles internes et externes et contribuent à renforcer la confiance dans la plateforme.